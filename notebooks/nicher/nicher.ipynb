{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDVSDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise GDVSDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gdal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from dea_datahandling import load_ard\n",
    "from dea_dask import create_local_dask_cluster\n",
    "from dea_plotting import display_map, rgb\n",
    "\n",
    "sys.path.append('./scripts')\n",
    "import gdvsdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare shapefiles and rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set shapefile paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set shapefile path and file location\n",
    "#occur_shp_path = r'./data_rf/bradypus/bradypus_p_webmerc.shp'\n",
    "occur_shp_path = r'./data_testing/yandi/points/presence_yandi_subset.shp'\n",
    "\n",
    "# example shapefile mask\n",
    "mask_shp_path = './data_rf/bradypus/sa_polymask_diss_webmerc.shp'\n",
    "\n",
    "# combine (only for validate)\n",
    "shp_path_list = [occur_shp_path,  mask_shp_path]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set raster paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "# in arcgis, on prompt, let them select raster layers cont and cat\n",
    "# we then bring in here as lists of file paths\n",
    "\n",
    "# example continous rasts\n",
    "\"\"\"\n",
    "rast_cont_list = [\n",
    "    './data_rf/tif/tmx6190_ann.tif',\n",
    "    './data_rf/tif/dtr6190_ann.tif',\n",
    "    './data_rf/tif/h_dem.tif',\n",
    "    './data_rf/tif/tmn6190_ann.tif',\n",
    "    './data_rf/tif/pre6190_l4.tif',\n",
    "    './data_rf/tif/vap6190_ann.tif',\n",
    "    './data_rf/tif/pre6190_l1.tif',\n",
    "    './data_rf/tif/cld6190_ann.tif',\n",
    "    './data_rf/tif/pre6190_l10.tif',\n",
    "    './data_rf/tif/pre6190_ann.tif',\n",
    "    './data_rf/tif/pre6190_l7.tif',\n",
    "    './data_rf/tif/tmp6190_ann.tif',\n",
    "    './data_rf/tif/frs6190_ann.tif'\n",
    "]\n",
    "\"\"\"\n",
    "rast_cont_list = [\n",
    "    './data_testing/yandi/rasters/aspect.tif',\n",
    "    './data_testing/yandi/rasters/curvature.tif',\n",
    "    './data_testing/yandi/rasters/dem_filled.tif',\n",
    "    './data_testing/yandi/rasters/dissection.tif',\n",
    "    './data_testing/yandi/rasters/eastness.tif',\n",
    "    './data_testing/yandi/rasters/hillshade.tif',\n",
    "    './data_testing/yandi/rasters/hli.tif',\n",
    "    './data_testing/yandi/rasters/northness.tif',\n",
    "    #'./data_testing/yandi/rasters/roughness.tif',\n",
    "    './data_testing/yandi/rasters/slope_deg.tif',\n",
    "    './data_testing/yandi/rasters/solar_rad.tif',\n",
    "    './data_testing/yandi/rasters/tpi.tif',\n",
    "    './data_testing/yandi/rasters/tri.tif',\n",
    "    './data_testing/yandi/rasters/twi.tif'\n",
    "]\n",
    "\n",
    "# example categorical rasts\n",
    "rast_cate_list = [\n",
    "    #'./data_rf/tif/ecoreg.tif'\n",
    "]\n",
    "\n",
    "# example combine\n",
    "rast_path_list = rast_cont_list + rast_cate_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run selected layers through validator, throw error if errors found\n",
    "gdvsdm.validate_input_data(shp_path_list, rast_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare species presence point locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read occurrence shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract point x and y from shapefile as numpy array\n",
    "df_presence = gdvsdm.read_coordinates_shp(occur_shp_path)\n",
    "\n",
    "# display result\n",
    "#print(df_presence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read mask shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mask polygon, dissolve it, output multipolygon geometry\n",
    "mask_geom = gdvsdm.read_mask_shp(mask_shp_path)\n",
    "\n",
    "# display result\n",
    "#print(mask_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rasters to xarray dataset (todo send to gdv_tools)\n",
    "ds = gdvsdm.rasters_to_dataset(rast_path_list)\n",
    "\n",
    "# display result\n",
    "#print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare species psuedo-absence point locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate psuedo-absence coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate absences using shapefile mask and occurrence coords\n",
    "#df_absence = gdvsdm.generate_absences_from_shp(mask_shp_path=mask_shp_path, num_abse=500, \n",
    "                                               #occur_shp_path=occur_shp_path, buff_m=50000)\n",
    "\n",
    "# generate absences using dataset pixels and occurrence coords\n",
    "df_absence = gdvsdm.generate_absences_from_dataset(ds=ds, num_abse=5000, occur_shp_path=occur_shp_path,\n",
    "                                                   buff_m=500, res_factor=3, nodata_value=-9999)\n",
    "\n",
    "# display result\n",
    "#print(df_absence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variable values at observed point locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values from dataset variables at each presence point coord\n",
    "df_presence_data = gdvsdm.extract_dataset_values(ds=ds, coords=df_presence, res_factor=3)\n",
    "\n",
    "# display result\n",
    "#print(df_presence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all records containing nodata values\n",
    "df_presence_data = gdvsdm.remove_nodata_records(df_presence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_presence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variable values at pseudoabsence point locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values from dataset variables at each presence point coord\n",
    "df_absence_data = gdvsdm.extract_dataset_values(ds=ds, coords=df_absence, res_factor=3)\n",
    "\n",
    "# display result\n",
    "#print(df_absence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all records containing nodata values\n",
    "df_absence_data = gdvsdm.remove_nodata_records(df_absence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_absence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalise records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalise absence to match number of presence\n",
    "#df_absence_data = gdvsdm.equalise_absence_records(df_presence_data, df_absence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_absence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine presence and absence records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take pres and abse records and combine, add new pres/abse column\n",
    "df_pres_abse_data = gdvsdm.combine_presence_absence_records(df_presence_data, df_absence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_pres_abse_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate variable correlation and variance inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Pearson's correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the matrix\n",
    "# rule of thumb: < 0.6 = weak collinearity, 0.6-0.8 = moderate, >= 0.8 = strong\n",
    "gdvsdm.generate_correlation_matrix(df_pres_abse_data, rast_cate_list, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Variance Inflation Factor (VIF) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the matrix\n",
    "# rule of thumb: 1 = No multicolinearity, 1-5 = moderate, > 5 = high, > 10 = Remove from model\n",
    "gdvsdm.generate_vif_scores(df_pres_abse_data, rast_cate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Species Distribution Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random forest estimator using default sklearn parameters\n",
    "estimator = gdvsdm.create_estimator(estimator_type='rf', n_estimators=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate SDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate SDM with 5 replicates and 10% training-testing split\n",
    "ds_sdm = gdvsdm.generate_sdm(ds, df_pres_abse_data, estimator, rast_cont_list, rast_cate_list, replicates=5, \n",
    "                             test_ratio=0.1, equalise_test_set=False, calc_accuracy_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display SDM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the sdm variable to display (i.e. sdm_mean, sdm_stdv, sdm_cvar)\n",
    "metric_name = 'sdm_mean'\n",
    "\n",
    "# create fig\n",
    "fig = plt.figure(figsize=(9, 7), dpi=85)\n",
    "\n",
    "# plot this on map\n",
    "ds_sdm[metric_name].plot(robust=False, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds_sdm[metric_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sdm.to_netcdf('yandi_sdm.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "# out crs\n",
    "crs = 'EPSG:3577'\n",
    "   \n",
    "# write tif\n",
    "write_cog(geo_im=da,\n",
    "          fname='yandi_sdm_mean.tif',\n",
    "          crs=crs,\n",
    "          nodata=-9999,\n",
    "          overwrite=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary dem retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the cluster. paste url into dask panel for more info.\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up a datacube connection\n",
    "dc = datacube.Datacube(app='gdvsdm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study area and data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set lat, lon (y, x) dictionary of testing areas for gdv project\n",
    "loc_dict = {\n",
    "    'test_a':   (-23.28043, 119.85931),\n",
    "    'test_b':   (-31.60693, 116.94264),\n",
    "    'test_c':   (-22.64623, 120.16237),\n",
    "    'test_d':   (-22.74596, 119.10474),\n",
    "}\n",
    "\n",
    "# set buffer length and height (x, y)\n",
    "buff_dict = {\n",
    "    'test_a': (0.5, 0.5),\n",
    "    'test_b': (0.5, 0.5),\n",
    "    'test_c': (0.5, 0.5),\n",
    "    'test_d': (0.25, 0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select location from dict\n",
    "study_area = 'test_d'\n",
    "\n",
    "# set buffer size in lon, lat (x, y)\n",
    "lon_buff, lat_buff = buff_dict[study_area][0], buff_dict[study_area][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a study area from existing dict\n",
    "lat, lon = loc_dict[study_area][0], loc_dict[study_area][1]\n",
    "\n",
    "# combine centroid with buffer to form study boundary\n",
    "lat_extent = (lat - lat_buff, lat + lat_buff)\n",
    "lon_extent = (lon - lon_buff, lon + lon_buff)\n",
    "\n",
    "# display onto interacrive map\n",
    "display_map(x=lon_extent, y=lat_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SRTM Digital Elevation Model (Resampled to 30m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query from above and expected info\n",
    "query = {\n",
    "    'x': lon_extent,\n",
    "    'y': lat_extent,\n",
    "    'measurements': ['dem'],\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (80, 80),\n",
    "    'group_by': 'solar_day',\n",
    "}\n",
    "\n",
    "\n",
    "# load srtm dem dataset # multi_scale_topographic_position\n",
    "ds_dem = dc.load(product='ga_srtm_dem1sv1_0', **query)\n",
    "\n",
    "# display dataset\n",
    "#print(ds_dem)\n",
    "\n",
    "# plot\n",
    "#ds_dem['dem'].plot(robust=True, cmap='terrain_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop time dimension and squeeze out time coordinate\n",
    "ds_dem = ds_dem.drop('time', errors='ignore')\n",
    "ds_dem = ds_dem.squeeze('time', drop=True)\n",
    "#ds_dem['dem'] = ds_dem['dem'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raster and reproject to match satellite dataset\n",
    "raster_path = './dem_80m.tif'\n",
    "raster_reprojected = rio_slurp_xarray(raster_path,\n",
    "                                      ds_10m.geobox,\n",
    "                                      resampling=\"bilinear\")\n",
    "\n",
    "# Set nodata to `NaN`\n",
    "raster_reprojected = mask_invalid_data(raster_reprojected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_10m['dem'] = raster_reprojected.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.algo import xr_reproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dem['dem'].attrs.get('nodata') = -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = ds_dem['dem'].attrs\n",
    "at['nodata'] = -9999\n",
    "ds_dem['dem'].attrs = at\n",
    "\n",
    "# import\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "# out crs\n",
    "crs = 'EPSG:3577'\n",
    "   \n",
    "# write tif\n",
    "write_cog(geo_im=ds_dem['dem'].astype('int16'),\n",
    "          fname='yandi_srtm_dem_30m.tif',\n",
    "          crs=crs,\n",
    "          overwrite=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
