{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nicher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Nicher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.7.2-CAPI-1.11.0 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import gdal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import datacube\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../../../Scripts')\n",
    "from dea_dask import create_local_dask_cluster\n",
    "from dea_plotting import display_map, rgb\n",
    "\n",
    "sys.path.append('../../modules')\n",
    "import nicher\n",
    "\n",
    "sys.path.append('../../shared')\n",
    "import satfetcher, tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 44185 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45975</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/lewis/proxy/44185/status' target='_blank'>/user/lewis/proxy/44185/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>13.11 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:45975' processes=1 threads=2, memory=13.11 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialise the cluster. paste url into dask panel for more info.\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load lower-res SRTM data resampled to 30m (ODC approach)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set study area, time range, show map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fbebcb665c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing study area extent - yandi and roy hill\n",
    "lat_extent, lon_extent = (-22.63461, -22.33461), (119.88111, 120.18111) # royhill\n",
    "\n",
    "# display onto interacrive map\n",
    "display_map(x=lon_extent, y=lat_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DEA ODC ARD satellite data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/datacube/drivers/postgres/_connections.py:87: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  username=username, password=password,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRTM Digital Elevation Model fetched successfully.\n"
     ]
    }
   ],
   "source": [
    "# provide study area name\n",
    "study_area = 'royhill'\n",
    "\n",
    "# fetch dem at 30 m resolution\n",
    "#ds_dem = satfetcher.load_dea_dem(x_extent=lon_extent, \n",
    "                                 #y_extent=lat_extent, \n",
    "                                 #resolution=30, \n",
    "                                 #use_dask=True)\n",
    "\n",
    "# display dataset\n",
    "#ds_dem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set raster paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: dem_srtm_30m_texture.tif\n",
      "Found: dem_srtm_30m_topo_wetness.tif\n",
      "Found: dem_srtm_30m_curvature.tif\n",
      "Found: dem_srtm_30m_fill.tif\n",
      "Found: dem_srtm_30m_aspect.tif\n",
      "Found: dem_srtm_30m_tri.tif\n",
      "Found: dem_srtm_30m_solar_rad.tif\n",
      "Found: dem_srtm_30m_mrrtf.tif\n",
      "Found: dem_srtm_30m_flow_acumm.tif\n",
      "Found: dem_srtm_30m_valley_depth.tif\n",
      "Found: dem_srtm_30m_lsfactor.tif\n",
      "Found: dem_srtm_30m_tpi.tif\n",
      "Found: dem_srtm_30m_saga_wetness.tif\n",
      "Found: dem_srtm_30m_convexity.tif\n",
      "Found: dem_srtm_30m.tif\n",
      "Found: dem_srtm_30m_mrvbf.tif\n",
      "Found: dem_srtm_30m_slope.tif\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "# get continuous rasters. we will do via arcgis eventually\n",
    "folder_path = r'../../data/nicher/roy_srtm'\n",
    "rast_cont_list = nicher.get_files_from_path(folder_path)\n",
    "\n",
    "# get categorical rasters. we don't have any!\n",
    "#folder_path = r'../../data/nicher/roy_srtm_cat'\n",
    "#rast_cate_list = nicher.get_files_from_path(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raster datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting rasters to an xarray dataset.\n",
      "Converted raster to xarray data array: dem_srtm_30m_texture\n",
      "Converted raster to xarray data array: dem_srtm_30m_topo_wetness\n",
      "Converted raster to xarray data array: dem_srtm_30m_curvature\n",
      "Converted raster to xarray data array: dem_srtm_30m_fill\n",
      "Converted raster to xarray data array: dem_srtm_30m_aspect\n",
      "Converted raster to xarray data array: dem_srtm_30m_tri\n",
      "Converted raster to xarray data array: dem_srtm_30m_solar_rad\n",
      "Converted raster to xarray data array: dem_srtm_30m_mrrtf\n",
      "Converted raster to xarray data array: dem_srtm_30m_flow_acumm\n",
      "Converted raster to xarray data array: dem_srtm_30m_valley_depth\n",
      "Converted raster to xarray data array: dem_srtm_30m_lsfactor\n",
      "Converted raster to xarray data array: dem_srtm_30m_tpi\n",
      "Converted raster to xarray data array: dem_srtm_30m_saga_wetness\n",
      "Converted raster to xarray data array: dem_srtm_30m_convexity\n",
      "Converted raster to xarray data array: dem_srtm_30m\n",
      "Converted raster to xarray data array: dem_srtm_30m_mrvbf\n",
      "Converted raster to xarray data array: dem_srtm_30m_slope\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Extracting CRS from dataset.\n",
      "CRS extracted successfully from dataset.\n",
      "Rasters converted to dataset successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = satfetcher.load_local_rasters(rast_path_list=rast_cont_list, \n",
    "                              use_dask=True, \n",
    "                              conform_nodata_to=-9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdvsdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2ed919ac698b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run selected layers through validator, throw error if errors found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgdvsdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshp_path_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrast_path_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gdvsdm' is not defined"
     ]
    }
   ],
   "source": [
    "# run selected layers through validator, throw error if errors found\n",
    "gdvsdm.validate_input_data(shp_path_list, rast_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set shapefile paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set shapefile path and file location\n",
    "occur_shp_path = r'../../data/nicher/points/presence_points/presence_points.shp'\n",
    "\n",
    "# combine (only for validate)\n",
    "shp_path_list = [occur_shp_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare species presence point locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read occurrence shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract point x and y from shapefile as numpy array\n",
    "df_presence = gdvsdm.read_coordinates_shp(occur_shp_path)\n",
    "\n",
    "# display result\n",
    "#print(df_presence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read mask shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mask polygon, dissolve it, output multipolygon geometry\n",
    "#mask_geom = gdvsdm.read_mask_shp(mask_shp_path)\n",
    "\n",
    "# display result\n",
    "#print(mask_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rasters to xarray dataset (todo send to gdv_tools)\n",
    "ds = gdvsdm.rasters_to_dataset(rast_path_list)\n",
    "\n",
    "# display result\n",
    "#print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare species psuedo-absence point locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate psuedo-absence coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate absences using shapefile mask and occurrence coords\n",
    "#df_absence = gdvsdm.generate_absences_from_shp(mask_shp_path=mask_shp_path, num_abse=500, \n",
    "                                               #occur_shp_path=occur_shp_path, buff_m=50000)\n",
    "\n",
    "# generate absences using dataset pixels and occurrence coords\n",
    "df_absence = gdvsdm.generate_absences_from_dataset(ds=ds, num_abse=5000, occur_shp_path=occur_shp_path,\n",
    "                                                   buff_m=500, res_factor=3, nodata_value=-9999)\n",
    "\n",
    "# display result\n",
    "#print(df_absence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variable values at observed point locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values from dataset variables at each presence point coord\n",
    "df_presence_data = gdvsdm.extract_dataset_values(ds=ds, coords=df_presence, res_factor=3)\n",
    "\n",
    "# display result\n",
    "#print(df_presence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all records containing nodata values\n",
    "df_presence_data = gdvsdm.remove_nodata_records(df_presence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_presence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract variable values at pseudoabsence point locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract values from dataset variables at each presence point coord\n",
    "df_absence_data = gdvsdm.extract_dataset_values(ds=ds, coords=df_absence, res_factor=3)\n",
    "\n",
    "# display result\n",
    "#print(df_absence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all records containing nodata values\n",
    "df_absence_data = gdvsdm.remove_nodata_records(df_absence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_absence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalise records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equalise absence to match number of presence\n",
    "#df_absence_data = gdvsdm.equalise_absence_records(df_presence_data, df_absence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_absence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine presence and absence records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take pres and abse records and combine, add new pres/abse column\n",
    "df_pres_abse_data = gdvsdm.combine_presence_absence_records(df_presence_data, df_absence_data)\n",
    "\n",
    "# display result\n",
    "#print(df_pres_abse_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate variable correlation and variance inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Pearson's correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the matrix\n",
    "# rule of thumb: < 0.6 = weak collinearity, 0.6-0.8 = moderate, >= 0.8 = strong\n",
    "gdvsdm.generate_correlation_matrix(df_pres_abse_data, rast_cate_list, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Variance Inflation Factor (VIF) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the matrix\n",
    "# rule of thumb: 1 = No multicolinearity, 1-5 = moderate, > 5 = high, > 10 = Remove from model\n",
    "gdvsdm.generate_vif_scores(df_pres_abse_data, rast_cate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Species Distribution Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random forest estimator using default sklearn parameters\n",
    "estimator = gdvsdm.create_estimator(estimator_type='rf', n_estimators=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate SDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate SDM with 5 replicates and 10% training-testing split\n",
    "ds_sdm = gdvsdm.generate_sdm(ds, df_pres_abse_data, estimator, rast_cont_list, rast_cate_list, replicates=5, \n",
    "                             test_ratio=0.1, equalise_test_set=False, calc_accuracy_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display SDM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the sdm variable to display (i.e. sdm_mean, sdm_stdv, sdm_cvar)\n",
    "metric_name = 'sdm_mean'\n",
    "\n",
    "# create fig\n",
    "fig = plt.figure(figsize=(9, 7), dpi=85)\n",
    "\n",
    "# plot this on map\n",
    "ds_sdm[metric_name].plot(robust=False, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds_sdm[metric_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sdm.to_netcdf('yandi_sdm.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "# out crs\n",
    "crs = 'EPSG:3577'\n",
    "   \n",
    "# write tif\n",
    "write_cog(geo_im=da,\n",
    "          fname='yandi_sdm_mean.tif',\n",
    "          crs=crs,\n",
    "          nodata=-9999,\n",
    "          overwrite=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary dem retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the cluster. paste url into dask panel for more info.\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up a datacube connection\n",
    "dc = datacube.Datacube(app='gdvsdm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study area and data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set lat, lon (y, x) dictionary of testing areas for gdv project\n",
    "loc_dict = {\n",
    "    'test_a':   (-23.28043, 119.85931),\n",
    "    'test_b':   (-31.60693, 116.94264),\n",
    "    'test_c':   (-22.64623, 120.16237),\n",
    "    'test_d':   (-22.74596, 119.10474),\n",
    "}\n",
    "\n",
    "# set buffer length and height (x, y)\n",
    "buff_dict = {\n",
    "    'test_a': (0.5, 0.5),\n",
    "    'test_b': (0.5, 0.5),\n",
    "    'test_c': (0.5, 0.5),\n",
    "    'test_d': (0.25, 0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select location from dict\n",
    "study_area = 'test_d'\n",
    "\n",
    "# set buffer size in lon, lat (x, y)\n",
    "lon_buff, lat_buff = buff_dict[study_area][0], buff_dict[study_area][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a study area from existing dict\n",
    "lat, lon = loc_dict[study_area][0], loc_dict[study_area][1]\n",
    "\n",
    "# combine centroid with buffer to form study boundary\n",
    "lat_extent = (lat - lat_buff, lat + lat_buff)\n",
    "lon_extent = (lon - lon_buff, lon + lon_buff)\n",
    "\n",
    "# display onto interacrive map\n",
    "display_map(x=lon_extent, y=lat_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SRTM Digital Elevation Model (Resampled to 30m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query from above and expected info\n",
    "query = {\n",
    "    'x': lon_extent,\n",
    "    'y': lat_extent,\n",
    "    'measurements': ['dem'],\n",
    "    'output_crs': 'EPSG:3577',\n",
    "    'resolution': (80, 80),\n",
    "    'group_by': 'solar_day',\n",
    "}\n",
    "\n",
    "\n",
    "# load srtm dem dataset # multi_scale_topographic_position\n",
    "ds_dem = dc.load(product='ga_srtm_dem1sv1_0', **query)\n",
    "\n",
    "# display dataset\n",
    "#print(ds_dem)\n",
    "\n",
    "# plot\n",
    "#ds_dem['dem'].plot(robust=True, cmap='terrain_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop time dimension and squeeze out time coordinate\n",
    "ds_dem = ds_dem.drop('time', errors='ignore')\n",
    "ds_dem = ds_dem.squeeze('time', drop=True)\n",
    "#ds_dem['dem'] = ds_dem['dem'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raster and reproject to match satellite dataset\n",
    "raster_path = './dem_80m.tif'\n",
    "raster_reprojected = rio_slurp_xarray(raster_path,\n",
    "                                      ds_10m.geobox,\n",
    "                                      resampling=\"bilinear\")\n",
    "\n",
    "# Set nodata to `NaN`\n",
    "raster_reprojected = mask_invalid_data(raster_reprojected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_10m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_10m['dem'] = raster_reprojected.astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from odc.algo import xr_reproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dem['dem'].attrs.get('nodata') = -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = ds_dem['dem'].attrs\n",
    "at['nodata'] = -9999\n",
    "ds_dem['dem'].attrs = at\n",
    "\n",
    "# import\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "# out crs\n",
    "crs = 'EPSG:3577'\n",
    "   \n",
    "# write tif\n",
    "write_cog(geo_im=ds_dem['dem'].astype('int16'),\n",
    "          fname='yandi_srtm_dem_30m.tif',\n",
    "          crs=crs,\n",
    "          overwrite=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
