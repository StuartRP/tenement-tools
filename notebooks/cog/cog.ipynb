{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise COG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import html\n",
    "import requests\n",
    "import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "sys.path.append('../../../Scripts')\n",
    "from dea_dask import create_local_dask_cluster\n",
    "\n",
    "sys.path.append('../../shared')\n",
    "import satfetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.6/site-packages/distributed/node.py:155: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38067 instead\n",
      "  http_address[\"port\"], self.http_server.port\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39203</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/lewis/proxy/38067/status' target='_blank'>/user/lewis/proxy/38067/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>13.11 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39203' processes=1 threads=2, memory=13.11 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialise the cluster\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get study area polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load study area geometry as geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read study area and get bounds as a list\n",
    "gdf = gpd.read_file('../../data/cog/yandisa.geojson')\n",
    "gdf_bounds = gdf.bounds.values[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set STAC Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get satellite collection on dea. todo get from user in arcgis, sentinel 2\n",
    "collections = [\n",
    "    'ga_ls5t_ard_3', \n",
    "    'ga_ls7e_ard_3',\n",
    "    'ga_ls8c_ard_3'\n",
    "]\n",
    "\n",
    "# set required bands\n",
    "bands = [\n",
    "    'oa_fmask',\n",
    "    'nbart_blue', \n",
    "    'nbart_green', \n",
    "    'nbart_red', \n",
    "    'nbart_nir',\n",
    "    'nbart_swir_1',\n",
    "    'nbart_swir_2'\n",
    "]\n",
    "\n",
    "# get satellite collection date range, convert to stac. todo get from user in arcgis\n",
    "start_dt, end_dt = '1990-01-01', '1995-12-31'\n",
    "\n",
    "# bring it all together for a query\n",
    "query = {\n",
    "    'collections': collections,\n",
    "    'datetime': '{0}/{1}'.format(start_dt, end_dt),\n",
    "    'bbox': gdf_bounds,\n",
    "    'query': {'eo:cloud_cover': {'lt': 5}}, #this doesnt work\n",
    "    'limit': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch DEA Public Data via STAC Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 146 satellite scenes in total.\n"
     ]
    }
   ],
   "source": [
    "# set stac endpoint\n",
    "search_endpoint = 'https://explorer.sandbox.dea.ga.gov.au/stac/search'\n",
    "\n",
    "# send and get request for stac json using \n",
    "stac_response = requests.post(search_endpoint, json=query)\n",
    "\n",
    "# check for response empty errors, convert to json if so\n",
    "if stac_response.ok:\n",
    "    stac_response = stac_response.json()\n",
    "    num_items = len(stac_response.get('features'))\n",
    "    print('Found {0} satellite scenes in total.'.format(num_items))\n",
    "else:\n",
    "    raise ValueError('Could not connect to DEA STAC SEARCH endpoint.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate STAC response and remove cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 10 satellite scenes due to clouds.\n",
      "Total of 136 satellite scenes remaining.\n"
     ]
    }
   ],
   "source": [
    "# set max cloud cover (0 - 100)\n",
    "max_cloud = 50\n",
    "\n",
    "# get num of all stac scenes\n",
    "num_all_items = len(stac_response.get('features'))\n",
    "\n",
    "feat_list = []\n",
    "for feat in stac_response.get('features'):\n",
    "    if max_cloud > float(feat.get('properties').get('eo:cloud_cover')):\n",
    "        feat_list.append(feat)\n",
    "        \n",
    "# count cloud less scenes and compare\n",
    "if feat_list:\n",
    "    num_clean_items = len(feat_list)\n",
    "    print('Removed {0} satellite scenes due to clouds.'.format(num_all_items - num_clean_items))\n",
    "    print('Total of {0} satellite scenes remaining.'.format(num_clean_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build VRTs for each scene in STAC response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting landsat vrts for each relevant bands.\n",
      "Building landsat vrt list for band: nbart_blue\n",
      "[30.0, 0.0, 565785.0, 0.0, -30.0, -2451285.0]\n",
      "| 30.00, 0.00, 565785.00|\n",
      "| 0.00,-30.00,-2451285.00|\n",
      "| 0.00, 0.00, 1.00|\n",
      "565785.0, 30.0, 0.0, -2451285.0, 0.0, -30.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-514b3b3517f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# get dict of band names and associated vrt lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mband_vrt_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dea_landsat_vrt_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-514b3b3517f7>\u001b[0m in \u001b[0;36mget_dea_landsat_vrt_dict\u001b[0;34m(feat_list)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# get list of vrts for band and add to dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mband_vrts_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msatfetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vrt_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# notify and return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tenement-tools/shared/satfetcher.py\u001b[0m in \u001b[0;36mbuild_vrt_list\u001b[0;34m(feat_list, band)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;31m# build a top-level vrt dataset xml object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "# meta, check\n",
    "def get_dea_landsat_vrt_dict(feat_list):\n",
    "    \"\"\"\n",
    "    this func is designed to take all releveant landsat bands\n",
    "    on the dea public database for each scene in stac query.\n",
    "    it results in a list of vrts for each band seperately and maps\n",
    "    them to a dict where band name is the key, list is the value pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    # imports\n",
    "    from osgeo import osr\n",
    "    \n",
    "    # notify\n",
    "    print('Getting landsat vrts for each relevant bands.')\n",
    "                        \n",
    "    # check features type, length\n",
    "    if not isinstance(feat_list, list):\n",
    "        raise TypeError('Features must be a list of xml objects.')\n",
    "    elif not len(feat_list) > 0:\n",
    "        raise ValueError('No features provided.')\n",
    "    \n",
    "    # required dea landsat ard band names\n",
    "    bands = [\n",
    "        'nbart_blue', \n",
    "        'nbart_green',\n",
    "        'nbart_red',\n",
    "        'nbart_nir',\n",
    "        'nbart_swir_1',\n",
    "        'nbart_swir_2',\n",
    "        'oa_mask'\n",
    "    ]\n",
    "    \n",
    "    # iter each band name and build vrt list\n",
    "    band_vrts_dict = {}\n",
    "    for band in bands:\n",
    "        print('Building landsat vrt list for band: {}'.format(band))\n",
    "        \n",
    "        # get list of vrts for band and add to dict\n",
    "        band_vrts_dict[band] = satfetcher.build_vrt_list(feat_list, band=band)\n",
    "        \n",
    "    # notify and return\n",
    "    print('Got landsat vrt lists for bands: {}'.format(band_vrts_dict.keys))\n",
    "    return band_vrts_dict\n",
    "    \n",
    "# get dict of band names and associated vrt lists\n",
    "band_vrt_dict = get_dea_landsat_vrt_dict(feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Wrong number or type of arguments for overloaded function 'new_CoordinateTransformation'.\n  Possible C/C++ prototypes are:\n    OSRCoordinateTransformationShadow::OSRCoordinateTransformationShadow(OSRSpatialReferenceShadow *,OSRSpatialReferenceShadow *)\n    OSRCoordinateTransformationShadow::OSRCoordinateTransformationShadow(OSRSpatialReferenceShadow *,OSRSpatialReferenceShadow *,OGRCoordinateTransformationOptions *)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-0b8a4264caf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mosgeo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mosr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mosr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinateTransformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m565785.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/env/lib/python3.6/site-packages/osgeo/osr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1386\u001b[0m         \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOSRCoordinateTransformationShadow\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpatialReference\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpatialReference\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCoordinateTransformationOptions\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCoordinateTransformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \"\"\"\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_osr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_CoordinateTransformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Wrong number or type of arguments for overloaded function 'new_CoordinateTransformation'.\n  Possible C/C++ prototypes are:\n    OSRCoordinateTransformationShadow::OSRCoordinateTransformationShadow(OSRSpatialReferenceShadow *,OSRSpatialReferenceShadow *)\n    OSRCoordinateTransformationShadow::OSRCoordinateTransformationShadow(OSRSpatialReferenceShadow *,OSRSpatialReferenceShadow *,OGRCoordinateTransformationOptions *)\n"
     ]
    }
   ],
   "source": [
    "from osgeo import osr\n",
    "osr.CoordinateTransformation(565785.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if bands in list\n",
    "\n",
    "\n",
    "# ensure requested bands allowed\n",
    "for b in bands:\n",
    "    if b not in allowed_bands:\n",
    "        raise ValueError('Requested an unsupported band.')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta, checks\n",
    "def build_dea_ard_vrts(platform=None, band=None):\n",
    "    \"\"\"\n",
    "    takes specific platform and band band names for dea public data\n",
    "    \"\"\"\n",
    "    \n",
    "    # checks\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "build_vrts(feat_list, band=['nbart_blue', 'nbart_red'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of bands needed\n",
    "wanted_bands = [\n",
    "    'nbart_blue', \n",
    "    'nbart_green',\n",
    "    'nbart_red',\n",
    "    'nbart_nir',\n",
    "    'nbart_swir_1',\n",
    "    'nbart_swir_1',\n",
    "    'oa_mask'\n",
    "]\n",
    "\n",
    "# build datetimes and vrts for each band\n",
    "#for band in wanted_bands:\n",
    "\n",
    "# todo, iterate this via list above\n",
    "vrt_blue = generate_vrt(feat_list=feat_list, band='nbart_blue')\n",
    "vrt_green = generate_vrt(feat_list=feat_list, band='nbart_green')\n",
    "vrt_red = generate_vrt(feat_list=feat_list, band='nbart_red')\n",
    "vrt_nir = generate_vrt(feat_list=feat_list, band='nbart_nir')\n",
    "vrt_swir_1 = generate_vrt(feat_list=feat_list, band='nbart_swir_1')\n",
    "vrt_swir_2 = generate_vrt(feat_list=feat_list, band='nbart_swir_2')\n",
    "vrt_mask = generate_vrt(feat_list=feat_list, band='oa_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an completed in-memory VRT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks, meta\n",
    "def create_vrt_file(vrt_files):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # checks\n",
    "    \n",
    "    # load up a temp named file and create vrt\n",
    "    with NamedTemporaryFile() as tmp:\n",
    "\n",
    "        # set vrt options\n",
    "        vrt_opts = gdal.BuildVRTOptions(separate=True,\n",
    "                                        #bandList=[1],\n",
    "                                        #outputBounds=boundingbox,\n",
    "                                        #resampleAlg='bilinear',\n",
    "                                        #resolution='user',\n",
    "                                        #xRes=30.0,\n",
    "                                        #yRes=30.0,\n",
    "                                        #outputSRS=rasterio.crs.CRS.from_epsg(3577).wkt\n",
    "                                        #targetAlignedPixels=True\n",
    "                                       )\n",
    "        \n",
    "        # build vrt, close it (to create it)\n",
    "        vrt_out = gdal.BuildVRT(tmp.name, vrt_files, options=vrt_opts)\n",
    "        vrt_out = None\n",
    "\n",
    "        # warp and translate funcs\n",
    "        # todo: MAY NEED\n",
    "\n",
    "        # read it in to memory and decode it\n",
    "        vrt = tmp.read().decode(\"utf-8\")\n",
    "        return vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small subset of raster in utm 50N\n",
    "#bb = [683100.0, -2542470.0, 686070.0, -2539500.0]\n",
    "\n",
    "# todo improve this code\n",
    "\n",
    "# create vrts\n",
    "vrt_blue_out = create_vrt_file(vrt_files=vrt_blue)\n",
    "vrt_green_out = create_vrt_file(vrt_files=vrt_green)\n",
    "vrt_red_out = create_vrt_file(vrt_files=vrt_red)\n",
    "vrt_nir_out = create_vrt_file(vrt_files=vrt_nir)\n",
    "vrt_swir_1_out = create_vrt_file(vrt_files=vrt_swir_1)\n",
    "vrt_swir_2_out = create_vrt_file(vrt_files=vrt_swir_2)\n",
    "vrt_mask_out = create_vrt_file(vrt_files=vrt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse datetime strings into map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datetimes(vrt_string):\n",
    "    \n",
    "    # convert html tags back out\n",
    "    clean_elem = html.unescape(vrt_blue_out)\n",
    "\n",
    "    # convert string to etree elements\n",
    "    root = etree.fromstring(clean_elem)\n",
    "\n",
    "    # pull descriptions out to get date times\n",
    "    elem_desc = root.findall('.//Description')\n",
    "\n",
    "    # iterate elements and pull description text\n",
    "    dt_map = {}\n",
    "    for i, e in enumerate(elem_desc, start=1):\n",
    "        dt_map[i] = e.text\n",
    "        \n",
    "    return dt_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vrts\n",
    "dt_blue = parse_datetimes(vrt_string=vrt_blue_out)\n",
    "dt_green = parse_datetimes(vrt_string=vrt_green_out)\n",
    "dt_red = parse_datetimes(vrt_string=vrt_red_out)\n",
    "dt_nir = parse_datetimes(vrt_string=vrt_nir_out)\n",
    "dt_swir_1 = parse_datetimes(vrt_string=vrt_swir_1_out)\n",
    "dt_swir_2 = parse_datetimes(vrt_string=vrt_swir_2_out)\n",
    "dt_mask = parse_datetimes(vrt_string=vrt_mask_out)\n",
    "\n",
    "# check if lengths are all same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to chunked dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xr_dataset(vrt_file, band_name):\n",
    "    \n",
    "    # setup chunks\n",
    "    chunks = {'band': 1, 'x': 'auto', 'y': 'auto'}\n",
    "    \n",
    "    # load xr as data array\n",
    "    ds = xr.open_rasterio(vrt_file, chunks=chunks)\n",
    "    \n",
    "    # rename default band label to time\n",
    "    ds = ds.rename({'band': 'time'})\n",
    "    \n",
    "    # convert to dataset\n",
    "    ds = ds.to_dataset(name=band_name, promote_attrs=True)\n",
    "    \n",
    "    # subset to coords, bb todo fix this up\n",
    "    ds = ds.isel(x=slice(4000, 5000), y=slice(3000, 4000))\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "ds_blue = build_xr_dataset(vrt_file=vrt_blue_out, band_name='nbart_blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace datetime\n",
    "def replace_datetimes(ds, dt):\n",
    "    \n",
    "    # replace timezone and convert numpy\n",
    "    dt_dict = {}\n",
    "    for k, v in dt_blue.items():\n",
    "        dt_dict[k] = np.datetime64(v.replace('Z', ''))\n",
    "    \n",
    "    # remap\n",
    "    ds['time'] = [dt_dict[i] for i in ds['time'].values.tolist()]\n",
    "    return ds.sortby('time')\n",
    "    \n",
    "ds_blue = replace_datetimes(ds_blue, dt_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute\n",
    "%time ds_blue = ds_blue.compute()\n",
    "ds_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all dask datasets into one\n",
    "#xr.merge([ds_blue, ds_green, ds_red])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test download times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try raw, without dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed testing without dask distributed\n",
    "%time ds = ds.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try raw, without dask but with threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed testing without dask distributed\n",
    "%time ds = ds.compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try raw, without dask but with processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed testing without dask distributed\n",
    "%time ds = ds.compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try dask, with distributed scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "client = Client(processes=True)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 47 secs with processes=false, 21 secs when True\n",
    "%time ds = ds.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try dask data arrays split and futures used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures \n",
    "\n",
    "# create compute func\n",
    "def compute_da(da):\n",
    "    return da.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split ds into seperate das\n",
    "da_list = []\n",
    "for dt in ds['time']:\n",
    "    da = ds.sel(time=dt)\n",
    "    da_list.append(da)\n",
    "    \n",
    "# try parallel load of all bands\n",
    "num_cores = 2\n",
    "with concurrent.futures.ThreadPoolExecutor(num_cores) as executor:\n",
    "    %time da_list = list(executor.map(compute_da, da_list))\n",
    "    \n",
    "ds = xr.concat(da_list, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this to auto gen vrt to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# really good test env\n",
    "vrt_1_urls = [\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band01.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band02.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band03.tif']\n",
    "vrt1 = gdal.BuildVRT('vrt_1.vrt', vrt_1_urls, separate=True).FlushCache()\n",
    "\n",
    " \n",
    "vrt_2_urls = [\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/03/13/ga_ls5t_nbart_3-0-0_112076_1990-03-13_final_band01.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/03/13/ga_ls5t_nbart_3-0-0_112076_1990-03-13_final_band02.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/03/13/ga_ls5t_nbart_3-0-0_112076_1990-03-13_final_band03.tif']\n",
    "vrt2 = gdal.BuildVRT('vrt_2.vrt', vrt_2_urls, separate=True).FlushCache()\n",
    "\n",
    "\n",
    "vrt_3_urls = [\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/111/076/1990/03/22/ga_ls5t_nbart_3-0-0_111076_1990-03-22_final_band01.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/111/076/1990/03/22/ga_ls5t_nbart_3-0-0_111076_1990-03-22_final_band02.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/111/076/1990/03/22/ga_ls5t_nbart_3-0-0_111076_1990-03-22_final_band03.tif']\n",
    "vrt3 = gdal.BuildVRT('vrt_3.vrt', vrt_3_urls, separate=True).FlushCache()\n",
    "\n",
    "\n",
    "vrt_4_urls = [\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/03/29/ga_ls5t_nbart_3-0-0_112076_1990-03-29_final_band01.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/03/29/ga_ls5t_nbart_3-0-0_112076_1990-03-29_final_band02.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/03/29/ga_ls5t_nbart_3-0-0_112076_1990-03-29_final_band03.tif']\n",
    "vrt4 = gdal.BuildVRT('vrt_4.vrt', vrt_4_urls, separate=True).FlushCache()\n",
    "\n",
    "# add to list\n",
    "vrt_list = ['vrt_1.vrt', 'vrt_2.vrt', 'vrt_3.vrt', 'vrt_4.vrt']\n",
    "vrt_out = gdal.BuildVRT('vrt_all.vrt', vrt_list, separate=False, bandList=[1]).FlushCache()\n",
    "\n",
    "\n",
    "# read it in to memory and decode it\n",
    "#vrt_all = tmp.read().decode(\"utf-8\")\n",
    "\n",
    "# setup chunks\n",
    "chunks = {'band': 1, 'x': 'auto', 'y': 'auto'}\n",
    "ds = xr.open_rasterio('vrt_all.vrt', chunks=chunks)\n",
    "ds = ds.isel(x=slice(2500, 3000), y=slice(2500, 3000))\n",
    "ds.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
