{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise COG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import html\n",
    "import requests\n",
    "import gdal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from lxml import etree\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "sys.path.append('../../../Scripts')\n",
    "from dea_dask import create_local_dask_cluster\n",
    "\n",
    "sys.path.append('../../shared')\n",
    "import satfetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42199</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/lewis/proxy/8787/status' target='_blank'>/user/lewis/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>13.11 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42199' processes=1 threads=2, memory=13.11 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialise the cluster\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load study area polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read study area\n",
    "#gdf = gpd.read_file('yandisa.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set STAC Search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get satellite collection on dea. todo get from user in arcgis, sentinel 2\n",
    "collections = [\n",
    "    'ga_ls5t_ard_3', \n",
    "    'ga_ls7e_ard_3',\n",
    "    'ga_ls8c_ard_3'\n",
    "]\n",
    "\n",
    "# set required bands\n",
    "bands = [\n",
    "    'oa_fmask',\n",
    "    'nbart_blue', \n",
    "    'nbart_green', \n",
    "    'nbart_red', \n",
    "    'nbart_nir',\n",
    "    'nbart_swir_1',\n",
    "    'nbart_swir_2'\n",
    "]\n",
    "\n",
    "# get satellite collection date range, convert to stac. todo get from user in arcgis\n",
    "start_dt, end_dt = '1990-01-01', '1995-12-31'\n",
    "\n",
    "# convert datetime strings to datetimes\n",
    "start_dt = datetime.strptime(start_dt, \"%Y-%m-%d\").strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "end_dt = datetime.strptime(end_dt, \"%Y-%m-%d\").strftime(\"%Y-%m-%dT00:00:00Z\")\n",
    "\n",
    "# bring it all together for a query\n",
    "query = {\n",
    "    'collections': collections,\n",
    "    'datetime': '{0}/{1}'.format(start_dt, end_dt),\n",
    "    'bbox': gdf.bounds.values[0].tolist(),\n",
    "    #'query': {'eo:cloud_cover': {'lt': 5}},\n",
    "    'limit': 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch DEA Public Data via STAC Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stac endpoint\n",
    "search_endpoint = 'https://explorer.sandbox.dea.ga.gov.au/stac/search'\n",
    "\n",
    "# send and get request for stac json using \n",
    "stac_response = requests.post(search_endpoint, json=query)\n",
    "\n",
    "# check for response empty errors, convert to json if so\n",
    "if stac_response.ok:\n",
    "    stac_response = stac_response.json()\n",
    "    num_items = len(stac_response.get('features'))\n",
    "    print('Found {0} satellite scenes in total.'.format(num_items))\n",
    "else:\n",
    "    raise ValueError('Could not connect to DEA STAC SEARCH endpoint.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate STAC response and remove cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max cloud cover (0 - 100)\n",
    "max_cloud = 25\n",
    "\n",
    "# get num of all stac scenes\n",
    "num_all_items = len(stac_response.get('features'))\n",
    "\n",
    "feat_list = []\n",
    "for feat in stac_response.get('features'):\n",
    "    if max_cloud > float(feat.get('properties').get('eo:cloud_cover')):\n",
    "        feat_list.append(feat)\n",
    "        \n",
    "# count cloud less scenes and compare\n",
    "if feat_list:\n",
    "    num_clean_items = len(feat_list)\n",
    "    print('Removed {0} satellite scenes due to clouds.'.format(num_all_items - num_clean_items))\n",
    "    print('Total of {0} satellite scenes remaining.'.format(num_clean_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set VRT Dataset and Raster generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_vrt_dataset(x_size, y_size, srs, transform):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # create vrt dataset xml element\n",
    "    xml_vrt = etree.Element('VRTDataset', \n",
    "                            rasterXSize=\"{}\".format(x_size),\n",
    "                            rasterYSize=\"{}\".format(y_size))\n",
    "\n",
    "    # create srs xml element\n",
    "    xml_srs = etree.Element('SRS',\n",
    "                            dataAxisToSRSAxisMapping=\"1,2\") # todo hardcoded\n",
    "    xml_srs.text = srs\n",
    "    xml_vrt.append(xml_srs)\n",
    "\n",
    "    # create geotransform xml element\n",
    "    xml_transform = etree.Element('GeoTransform')\n",
    "    xml_transform.text = transform\n",
    "    xml_vrt.append(xml_transform)\n",
    "\n",
    "    # create metadata xml element\n",
    "    #xml_meta = etree.Element('Metadata')\n",
    "    \n",
    "    # add test metadata item\n",
    "    #xml_meta_dt = etree.Element('MDI', key=\"TIFFTAG_DATETIME\")\n",
    "    #xml_meta_dt.text = \"{}\".format(\"2012-01-01\")\n",
    "    #xml_meta.append(xml_meta_dt)\n",
    "    \n",
    "    # add meta to vrt xml\n",
    "    #xml_vrt.append(xml_meta)\n",
    "    \n",
    "    return xml_vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_vrt_raster(x_size, y_size, dtype, dt, url, relative_to, band_num, nodata):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # check types\n",
    "    \n",
    "    # create vrt dataset xml element\n",
    "    xml_rast = etree.Element('VRTRasterBand', \n",
    "                             dataType=\"{}\".format(dtype),\n",
    "                             band=\"{}\".format(band_num))\n",
    "    \n",
    "    # create nodata xml element\n",
    "    xml_nodata = etree.Element('NoDataValue')\n",
    "    xml_nodata.text = '{}'.format(nodata)\n",
    "    xml_rast.append(xml_nodata)\n",
    "    \n",
    "    # create raster description xml element\n",
    "    xml_desc = etree.Element('Description')\n",
    "    xml_desc.text = '{}'.format(dt)\n",
    "    xml_rast.append(xml_desc)\n",
    "      \n",
    "    # create simple source xml element\n",
    "    xml_complex = etree.Element('ComplexSource')\n",
    "\n",
    "    # create SourceFilename xml element\n",
    "    xml_filename = etree.Element('SourceFilename',\n",
    "                                 relativeToVRT=\"{}\".format(relative_to))\n",
    "    xml_filename.text = '/vsicurl/{}'.format(url)\n",
    "    xml_complex.append(xml_filename)\n",
    "\n",
    "    # create simple source xml element\n",
    "    xml_band = etree.Element('SourceBand')\n",
    "    xml_band.text = '{}'.format(band_num)  # was 1, as official vrtbuilder does it, but this helps id\n",
    "    xml_complex.append(xml_band)\n",
    "    \n",
    "    # create SourceProperties xml element\n",
    "    xml_props = etree.Element('SourceProperties',\n",
    "                              rasterXSize=\"{}\".format(x_size),\n",
    "                              rasterYSize=\"{}\".format(y_size),\n",
    "                              DataType=\"{}\".format(dtype),\n",
    "                              BlockXSize=\"{}\".format(512),\n",
    "                              BlockYSize=\"{}\".format(512))\n",
    "    xml_complex.append(xml_props)\n",
    "\n",
    "    # create source rect xml element\n",
    "    xml_src_rect = etree.Element('SrcRect',\n",
    "                                 xOff=\"{}\".format(0),\n",
    "                                 yOff=\"{}\".format(0),\n",
    "                                 xSize=\"{}\".format(x_size),\n",
    "                                 ySize=\"{}\".format(y_size))\n",
    "    xml_complex.append(xml_src_rect)\n",
    "    \n",
    "    # create destination rect xml element\n",
    "    xml_dst_rect = etree.Element('DstRect',\n",
    "                                 xOff=\"{}\".format(0),\n",
    "                                 yOff=\"{}\".format(0),\n",
    "                                 xSize=\"{}\".format(x_size),\n",
    "                                 ySize=\"{}\".format(y_size))\n",
    "    xml_complex.append(xml_dst_rect)\n",
    "    \n",
    "    # create nodata xml element\n",
    "    xml_src_nodata = etree.Element('NODATA')\n",
    "    xml_src_nodata.text = '{}'.format(nodata)\n",
    "    xml_complex.append(xml_src_nodata)\n",
    "        \n",
    "    # add simple element to raster element as child\n",
    "    xml_rast.append(xml_complex)\n",
    "    \n",
    "    return xml_rast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill VRT temmplate with values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo checks, meta\n",
    "def generate_vrt(feat_list, band=None):\n",
    "    \"\"\"\n",
    "    band : list, str\n",
    "        Can be a list or string of name of band(s) required.\n",
    "    \"\"\"\n",
    "        \n",
    "    # check if band provided, if so and is str, make list\n",
    "    if band is None:\n",
    "        bands = []\n",
    "    elif not isinstance(band, list):\n",
    "        bands = [band]\n",
    "    else:\n",
    "        bands = band\n",
    "        \n",
    "    # check if bands in list\n",
    "    allowed_bands = [\n",
    "        'nbart_blue', \n",
    "        'nbart_green',\n",
    "        'nbart_red',\n",
    "        'nbart_nir',\n",
    "        'nbart_swir_1',\n",
    "        'nbart_swir_2',\n",
    "        'oa_mask'\n",
    "    ]\n",
    "    \n",
    "    # ensure requested bands allowed\n",
    "    for b in bands:\n",
    "        if b not in allowed_bands:\n",
    "            raise ValueError('Requested an unsupported band.')\n",
    "            \n",
    "    # check features type, length\n",
    "    if not isinstance(feat_list, list):\n",
    "        raise TypeError('Features must be a list of xml objects.')\n",
    "    elif not len(feat_list) > 0:\n",
    "        raise ValueError('No features provided.')\n",
    "\n",
    "    # set list vrt of each scene\n",
    "    vrt_list = []\n",
    "\n",
    "    # iter stac scenes, get metadata, insert bands into vrt template\n",
    "    for feat_idx, feat in enumerate(feat_list, start=1):\n",
    "\n",
    "        # get scene identity and properties\n",
    "        f_id = feat.get('id')\n",
    "        f_props = feat.get('properties')\n",
    "\n",
    "        # get scene-level date\n",
    "        f_dt = f_props.get('datetime')\n",
    "\n",
    "        # get scene-level x, y parameters\n",
    "        f_x_size = f_props.get('proj:shape')[1]\n",
    "        f_y_size = f_props.get('proj:shape')[0]\n",
    "\n",
    "        # get scene-level epsg src as wkt\n",
    "        f_srs = rasterio.crs.CRS.from_epsg(f_props.get('proj:epsg')).wkt\n",
    "\n",
    "        # get scene-level transform\n",
    "        aff = rasterio.transform.Affine(*f_props.get('proj:transform')[0:6])\n",
    "        f_transform = ', '.join(str(p) for p in rasterio.transform.Affine.to_gdal(aff))\n",
    "\n",
    "        # generate vrt dataset \n",
    "        vrt_xml = build_vrt_dataset(x_size=f_x_size, \n",
    "                                    y_size=f_y_size, \n",
    "                                    srs=f_srs, \n",
    "                                    transform=f_transform)\n",
    "\n",
    "        # iterate bands and add to vrt if exists\n",
    "        band_idx = 1\n",
    "        for band in bands:\n",
    "            if band in feat.get('assets'):\n",
    "\n",
    "                # get asset\n",
    "                asset = feat.get('assets').get(band)\n",
    "\n",
    "                # set dtype to in16 unless mask\n",
    "                a_dtype = 'Int8' if band == 'oa_mask' else 'Int16'\n",
    "\n",
    "                # get asset raster x, y sizes\n",
    "                a_x_size = asset.get('proj:shape')[1]\n",
    "                a_y_size = asset.get('proj:shape')[0]\n",
    "\n",
    "                # get raster url, replace s3 with https\n",
    "                a_url = asset.get('href')\n",
    "                a_url = a_url.replace('s3://dea-public-data', 'https://data.dea.ga.gov.au')\n",
    "\n",
    "                # get epsg as wkt\n",
    "                #srs = rasterio.crs.CRS.from_epsg(f_epsg).wkt\n",
    "\n",
    "                # get transform (six params) as string\n",
    "                aff = rasterio.transform.Affine(*asset.get('proj:transform')[0:6])\n",
    "                a_transform = ', '.join(str(p) for p in rasterio.transform.Affine.to_gdal(aff))\n",
    "\n",
    "                # get nodata value\n",
    "                a_nodata = -999\n",
    "\n",
    "                # build raster xml\n",
    "                rast_xml = build_vrt_raster(x_size=a_x_size, \n",
    "                                            y_size=a_y_size, \n",
    "                                            dtype=a_dtype, \n",
    "                                            dt=f_dt,\n",
    "                                            url=a_url, \n",
    "                                            relative_to=1, \n",
    "                                            band_num=band_idx, \n",
    "                                            nodata=a_nodata)\n",
    "\n",
    "                # add raster xml to vrt dataset xml as child\n",
    "                vrt_xml.append(rast_xml)\n",
    "\n",
    "                # increase band index\n",
    "                band_idx += 1\n",
    "\n",
    "        # decode to utf-8 string and append to vrt list\n",
    "        vrt_str = etree.tostring(vrt_xml).decode('utf-8')\n",
    "        vrt_list.append(vrt_str)\n",
    "        \n",
    "    return vrt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of bands needed\n",
    "wanted_bands = [\n",
    "    'nbart_blue', \n",
    "    'nbart_green',\n",
    "    'nbart_red',\n",
    "    'nbart_nir',\n",
    "    'nbart_swir_1',\n",
    "    'nbart_swir_1',\n",
    "    'oa_mask'\n",
    "]\n",
    "\n",
    "# build datetimes and vrts for each band\n",
    "#for band in wanted_bands:\n",
    "\n",
    "# todo, iterate this via list above\n",
    "vrt_blue = generate_vrt(feat_list=feat_list, band='nbart_blue')\n",
    "vrt_green = generate_vrt(feat_list=feat_list, band='nbart_green')\n",
    "vrt_red = generate_vrt(feat_list=feat_list, band='nbart_red')\n",
    "vrt_nir = generate_vrt(feat_list=feat_list, band='nbart_nir')\n",
    "vrt_swir_1 = generate_vrt(feat_list=feat_list, band='nbart_swir_1')\n",
    "vrt_swir_2 = generate_vrt(feat_list=feat_list, band='nbart_swir_2')\n",
    "vrt_mask = generate_vrt(feat_list=feat_list, band='oa_mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an completed in-memory VRT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks, meta\n",
    "def create_vrt_file(vrt_files):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # checks\n",
    "    \n",
    "    # load up a temp named file and create vrt\n",
    "    with NamedTemporaryFile() as tmp:\n",
    "\n",
    "        # set vrt options\n",
    "        vrt_opts = gdal.BuildVRTOptions(separate=True,\n",
    "                                        #bandList=[1],\n",
    "                                        #outputBounds=boundingbox,\n",
    "                                        #resampleAlg='bilinear',\n",
    "                                        #resolution='user',\n",
    "                                        #xRes=30.0,\n",
    "                                        #yRes=30.0,\n",
    "                                        #outputSRS=rasterio.crs.CRS.from_epsg(3577).wkt\n",
    "                                        #targetAlignedPixels=True\n",
    "                                       )\n",
    "        \n",
    "        # build vrt, close it (to create it)\n",
    "        vrt_out = gdal.BuildVRT(tmp.name, vrt_files, options=vrt_opts)\n",
    "        vrt_out = None\n",
    "\n",
    "        # warp and translate funcs\n",
    "        # todo: MAY NEED\n",
    "\n",
    "        # read it in to memory and decode it\n",
    "        vrt = tmp.read().decode(\"utf-8\")\n",
    "        return vrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small subset of raster in utm 50N\n",
    "#bb = [683100.0, -2542470.0, 686070.0, -2539500.0]\n",
    "\n",
    "# todo improve this code\n",
    "\n",
    "# create vrts\n",
    "vrt_blue_out = create_vrt_file(vrt_files=vrt_blue)\n",
    "vrt_green_out = create_vrt_file(vrt_files=vrt_green)\n",
    "vrt_red_out = create_vrt_file(vrt_files=vrt_red)\n",
    "vrt_nir_out = create_vrt_file(vrt_files=vrt_nir)\n",
    "vrt_swir_1_out = create_vrt_file(vrt_files=vrt_swir_1)\n",
    "vrt_swir_2_out = create_vrt_file(vrt_files=vrt_swir_2)\n",
    "vrt_mask_out = create_vrt_file(vrt_files=vrt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse datetime strings into map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datetimes(vrt_string):\n",
    "    \n",
    "    # convert html tags back out\n",
    "    clean_elem = html.unescape(vrt_blue_out)\n",
    "\n",
    "    # convert string to etree elements\n",
    "    root = etree.fromstring(clean_elem)\n",
    "\n",
    "    # pull descriptions out to get date times\n",
    "    elem_desc = root.findall('.//Description')\n",
    "\n",
    "    # iterate elements and pull description text\n",
    "    dt_map = {}\n",
    "    for i, e in enumerate(elem_desc, start=1):\n",
    "        dt_map[i] = e.text\n",
    "        \n",
    "    return dt_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vrts\n",
    "dt_blue = parse_datetimes(vrt_string=vrt_blue_out)\n",
    "dt_green = parse_datetimes(vrt_string=vrt_green_out)\n",
    "dt_red = parse_datetimes(vrt_string=vrt_red_out)\n",
    "dt_nir = parse_datetimes(vrt_string=vrt_nir_out)\n",
    "dt_swir_1 = parse_datetimes(vrt_string=vrt_swir_1_out)\n",
    "dt_swir_2 = parse_datetimes(vrt_string=vrt_swir_2_out)\n",
    "dt_mask = parse_datetimes(vrt_string=vrt_mask_out)\n",
    "\n",
    "# check if lengths are all same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to chunked dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xr_dataset(vrt_file, band_name):\n",
    "    \n",
    "    # setup chunks\n",
    "    chunks = {'band': 1, 'x': 'auto', 'y': 'auto'}\n",
    "    \n",
    "    # load xr as data array\n",
    "    ds = xr.open_rasterio(vrt_file, chunks=chunks)\n",
    "    \n",
    "    # rename default band label to time\n",
    "    ds = ds.rename({'band': 'time'})\n",
    "    \n",
    "    # convert to dataset\n",
    "    ds = ds.to_dataset(name=band_name, promote_attrs=True)\n",
    "    \n",
    "    # subset to coords, bb todo fix this up\n",
    "    ds = ds.isel(x=slice(4000, 5000), y=slice(3000, 4000))\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "ds_blue = build_xr_dataset(vrt_file=vrt_blue_out, band_name='nbart_blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace datetime\n",
    "def replace_datetimes(ds, dt):\n",
    "    \n",
    "    # replace timezone and convert numpy\n",
    "    dt_dict = {}\n",
    "    for k, v in dt_blue.items():\n",
    "        dt_dict[k] = np.datetime64(v.replace('Z', ''))\n",
    "    \n",
    "    # remap\n",
    "    ds['time'] = [dt_dict[i] for i in ds['time'].values.tolist()]\n",
    "    return ds.sortby('time')\n",
    "    \n",
    "ds_blue = replace_datetimes(ds_blue, dt_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute\n",
    "%time ds_blue = ds_blue.compute()\n",
    "ds_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all dask datasets into one\n",
    "#xr.merge([ds_blue, ds_green, ds_red])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test download times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try raw, without dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed testing without dask distributed\n",
    "%time ds = ds.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try raw, without dask but with threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed testing without dask distributed\n",
    "%time ds = ds.compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try raw, without dask but with processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed testing without dask distributed\n",
    "%time ds = ds.compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try dask, with distributed scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "client = Client(processes=True)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# about 47 secs with processes=false, 21 secs when True\n",
    "%time ds = ds.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try dask data arrays split and futures used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures \n",
    "\n",
    "# create compute func\n",
    "def compute_da(da):\n",
    "    return da.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split ds into seperate das\n",
    "da_list = []\n",
    "for dt in ds['time']:\n",
    "    da = ds.sel(time=dt)\n",
    "    da_list.append(da)\n",
    "    \n",
    "# try parallel load of all bands\n",
    "num_cores = 2\n",
    "with concurrent.futures.ThreadPoolExecutor(num_cores) as executor:\n",
    "    %time da_list = list(executor.map(compute_da, da_list))\n",
    "    \n",
    "ds = xr.concat(da_list, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this to auto gen vrt to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band02.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band03.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band04.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band05.tif',\n",
    "    '/vsicurl/https://data.dea.ga.gov.au/baseline/ga_ls5t_ard_3/112/076/1990/02/09/ga_ls5t_nbart_3-0-0_112076_1990-02-09_final_band06.tif'\n",
    "]\n",
    "\n",
    "with NamedTemporaryFile() as tmp:\n",
    "    out = gdal.BuildVRT('hey.vrt', \n",
    "                        urls, urls), \n",
    "                        #xRes=10.0,\n",
    "                        #yRes=10.0,\n",
    "                        #outputSRS=rasterio.crs.CRS.from_epsg(3577).wkt,\n",
    "                        #outputBounds=bb, \n",
    "                        #resolution='highest', \n",
    "                        #resampleAlg='near',\n",
    "                        separate=True,\n",
    "                        )\n",
    "    out = None\n",
    "\n",
    "    v = tmp.read().decode(\"utf-8\")\n",
    "\n",
    "#xr.open_rasterio(v).to_dataset(dim='band')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
