# -*- coding: utf-8 -*-# https://pro.arcgis.com/en/pro-app/latest/arcpy/geoprocessing_and_python/a-quick-tour-of-python-toolboxes.htm# imports todo - fix this up properlyimport os, certifios.environ['GDAL_DATA']  = r'C:\Program Files\ArcGIS\Pro\Resources\pedata\gdaldata'os.environ.setdefault("CURL_CA_BUNDLE", certifi.where())# importsimport arcpyclass Toolbox(object):    def __init__(self):        """Define the toolbox (the name of the toolbox is the name of the        .pyt file)."""           self.label = "Toolbox"        self.alias = "toolbox"        # list of tool classes associated with this toolbox        self.tools = [Tool, COG_Fetch, GDVSpectra]        class Tool(object):    def __init__(self):        """Define the tool (tool name is the name of the class)."""        self.label = "Tool"        self.description = ""        self.canRunInBackground = False    def getParameterInfo(self):        """Define parameter definitions"""        params = None        return params    def isLicensed(self):        """Set whether tool is licensed to execute."""        return True    def updateParameters(self, parameters):        """Modify the values and properties of parameters before internal        validation is performed.  This method is called whenever a parameter        has been changed."""        return    def updateMessages(self, parameters):        """Modify the messages created by internal validation for each tool        parameter.  This method is called after internal validation."""        return    def execute(self, parameters, messages):        """The source code of the tool."""        returnclass COG_Fetch(object):    def __init__(self):        """Define the tool (tool name is the name of the class)."""              self.label = "COG Fetch"        self.description = "COG contains functions that " \                           "allow for efficient download of " \                           "analysis ready data (ARD) Landsat " \                           "5, 7, 8 or Sentinel 2A, 2B images " \                           "from the Digital Earth Australia " \                           "(DEA) public AWS server."        self.canRunInBackground = False    def getParameterInfo(self):                # input study area shapefile        par_studyarea_feat = arcpy.Parameter(                                displayName="Input study area feature",                                name="in_studyarea_feat",                                datatype="GPFeatureLayer",                                parameterType="Required",                                direction="Input"                                )                                        # set study area to be polygon only        par_studyarea_feat.filter.list = ['Polygon']                                        # output folder location        par_out_folder_path = arcpy.Parameter(                                displayName="Output folder",                                name="out_folder_path",                                datatype="DEWorkspace",                                parameterType="Required",                                direction="Input"                                )        # in_platform        par_platform = arcpy.Parameter(                            displayName="Satellite platform",                            name="in_platform",                            datatype="GPString",                            parameterType="Required",                            direction="Input",                            multiValue=False                            )                                    # set default platform        par_platform.values = 'Landsat'        par_platform.filter.list = ['Landsat', 'Sentinel']                # in_from_date        par_date_from = arcpy.Parameter(                            displayName="Date from",                            name="in_from_date",                            datatype="GPDate",                            parameterType="Required",                            direction="Input",                            multiValue=False                            )                                    # set in_from_date value        par_date_from.values = '2015/01/01'                # in_to_date        par_date_to = arcpy.Parameter(                        displayName="Date to",                        name="in_to_date",                        datatype="GPDate",                        parameterType="Required",                        direction="Input",                        multiValue=False                        )        # set in_from_date value        par_date_to.values = '2019/12/31'        # set bands        par_bands = arcpy.Parameter(                        displayName="Bands",                        name="in_bands",                        datatype="GPString",                        parameterType="Required",                        direction="Input",                        category='Satellite Bands',                        multiValue=True                        )                         # set landsat bands        bands = [            'Blue',             'Green',             'Red',             'NIR',             'SWIR1',             'SWIR2',             'OA_Mask'            ]                # set default bands        par_bands.filter.type = "ValueList"                par_bands.filter.list = bands        par_bands.values = bands                # set slc-off        par_slc_off = arcpy.Parameter(                        displayName="SLC Off",                        name="in_slc_off",                        datatype="GPBoolean",                        parameterType="Required",                        direction="Input",                        multiValue=False                        )                # set slc-off value        par_slc_off.value = False                # set oa class values        par_fmask_flags = arcpy.Parameter(displayName="Include flags",                                            name="in_fmask_flags",                                            datatype="GPString",                                            parameterType="Required",                                            direction="Input",                                            category='Quality Options',                                            multiValue=True                                          )        # set landsat bands        fmask_flags = [            'NoData',             'Valid',             'Cloud',             'Shadow',             'Snow',             'Water'            ]                # set default bands        par_fmask_flags.filter.type = "ValueList"                par_fmask_flags.filter.list = fmask_flags        par_fmask_flags.values = ['Valid', 'Snow', 'Water']                # max cloud cover        par_max_cloud = arcpy.Parameter(                            displayName="Maximum cloud cover",                            name="in_max_cloud",                            datatype="GPDouble",                            parameterType="Optional",                            direction="Input",                            category='Quality Options',                            multiValue=False                            )                                    # set default platform        par_max_cloud.filter.type = 'Range'        par_max_cloud.filter.list = [0.0, 100.0]        par_max_cloud.value = 10.0                # set open as multidim raster values        par_open_as_mdr = arcpy.Parameter(                            displayName="Open as Multidimensional Raster",                            name="in_open_as_mdr",                            datatype="GPBoolean",                            parameterType="Optional",                            direction="Input",                            category='Output Options',                            multiValue=False                            )                # set multidim raster value        par_open_as_mdr.value = True                # set output datatype        par_output_dtype = arcpy.Parameter(                            displayName="Output data type",                            name="in_output_dtype",                            datatype="GPString",                            parameterType="Required",                            direction="Input",                            category='Warping Options',                            multiValue=False                            )                                    # set default platform        par_output_dtype.filter.list = ['int8', 'int16', 'float32', 'float64']        par_output_dtype.values = 'int16'                # todo make this changeh when sent/landsat changed        # set output resolution        par_output_res = arcpy.Parameter(                            displayName="Output pixel resolution",                            name="in_output_res",                            datatype="GPLong",                            parameterType="Required",                            direction="Input",                            category='Warping Options',                            multiValue=False                            )                                    # set default platform        par_output_res.filter.type = 'Range'        par_output_res.filter.list = [0, 1000]        par_output_res.value = 30         # todo allow this to handle np.nan        # set output nodata value        par_output_fill_value = arcpy.Parameter(                                    displayName="Output NoData value",                                    name="in_output_fill_value",                                    datatype="GPString",                                    parameterType="Required",                                    direction="Input",                                    category='Warping Options',                                    multiValue=False                                    )                                    # set default nodata value        par_output_fill_value.value = "-999"                # set output epsg        par_output_epsg = arcpy.Parameter(                            displayName="Output EPSG",                            name="in_output_epsg",                            datatype="GPLong",                            parameterType="Required",                            direction="Input",                            category='Warping Options',                            multiValue=False                            )                                    # set default epsg        par_output_epsg.filter.list = [3577]        par_output_epsg.values = 3577                # set resampling type        par_output_resampling = arcpy.Parameter(                            displayName="Resampling type",                            name="in_output_resampling",                            datatype="GPString",                            parameterType="Required",                            direction="Input",                            category='Warping Options',                            multiValue=False                            )                                    # set default resampling        par_output_resampling.filter.list = ['Nearest', 'Bilinear']        par_output_resampling.values = 'Nearest'                # set snap boundary        par_output_snap = arcpy.Parameter(                            displayName="Snap boundaries",                            name="in_snap_bounds",                            datatype="GPBoolean",                            parameterType="Required",                            direction="Input",                            category='Warping Options',                            multiValue=False                            )                # set snap boundary value        par_output_snap.value = True                # set rescale        par_output_rescale = arcpy.Parameter(                        displayName="Rescale",                        name="in_rescale",                        datatype="GPBoolean",                        parameterType="Required",                        direction="Input",                        category='Warping Options',                        multiValue=False                        )                # set rescale value        par_output_rescale.value = True                # set cell alignment        par_output_cell_align = arcpy.Parameter(                            displayName="Cell alignment",                            name="in_output_cell_align",                            datatype="GPString",                            parameterType="Required",                            direction="Input",                            category='Warping Options',                            multiValue=False                            )                                    # set default cell align        par_output_cell_align.filter.list = ['Top-left', 'Center']        par_output_cell_align.values = 'Top-left'                # set chunks        par_output_chunk_size = arcpy.Parameter(                            displayName="Chunk size",                            name="in_output_chunk_size",                            datatype="GPLong",                            parameterType="Required",                            direction="Input",                            category='Parallelisation',                            multiValue=False                            )                                    # set default platform        par_output_chunk_size.value = -1                # combine parameters        parameters = [            par_studyarea_feat,            par_out_folder_path,            par_platform,            par_date_from,            par_date_to,            par_bands,            par_slc_off,            par_fmask_flags,            par_max_cloud,            par_open_as_mdr,            par_output_dtype,            par_output_res,            par_output_fill_value,            par_output_epsg,            par_output_resampling,            par_output_snap,            par_output_rescale,            par_output_cell_align,            par_output_chunk_size        ]                return parameters    def isLicensed(self):        """Set whether tool is licensed to execute."""        return True    def updateParameters(self, parameters):        """Modify the values and properties of parameters before internal        validation is performed.  This method is called whenever a parameter        has been changed."""        return    def updateMessages(self, parameters):        """Modify the messages created by internal validation for each tool        parameter.  This method is called after internal validation."""        return    def execute(self, parameters, messages):                # imports todo - fix this up properly        import os, certifi        os.environ['GDAL_DATA']  = r'C:\Program Files\ArcGIS\Pro\Resources\pedata\gdaldata'        os.environ.setdefault("CURL_CA_BUNDLE", certifi.where())                        # imports        import os, sys        import io        import time        import numpy as np        import xarray as xr        import dask        import dask.array as da        import arcpy        # import tools        #sys.path.append('../../../shared') temp for demo        #sys.path.append(r'C:\Users\262272G\Documents\GitHub\tenement-tools\shared')        sys.path.append(r'C:\Users\Lewis\Documents\GitHub\tenement-tools\shared')        import arc                # import gdvspectra module        #sys.path.append('../../../modules') temp for demo        #sys.path.append(r'C:\Users\262272G\Documents\GitHub\tenement-tools\modules')        sys.path.append(r'C:\Users\Lewis\Documents\GitHub\tenement-tools\modules')        import cog                # globals         AWS_KEY = ''        AWS_SECRET = ''        STAC_ENDPOINT = 'https://explorer.sandbox.dea.ga.gov.au/stac/search'        RESULT_LIMIT = 250                # notify         arcpy.AddMessage('Performing COG Fetch.')                                                    # grab parameter values         in_studyarea_feat = parameters[0].value         # study area feat         out_folder_path = parameters[1].valueAsText     # output folder         in_platform = parameters[2].value               # platform name        in_from_date = parameters[3].value              # from date        in_to_date = parameters[4].value                # to date        in_bands = parameters[5].valueAsText            # bands        in_slc_off = parameters[6].value                # slc off         in_fmask_flags = parameters[7].value            # fmask flag values        in_max_cloud = parameters[8].value              # max cloud percentage        in_open_as_mdr = parameters[9].value            # open output netcdf as mdr        in_dtype = parameters[10].value                 # output pixel dtype        in_res = parameters[11].value                   # output pixel resolution        in_fill_value = parameters[12].value            # todo processing string to int, float or np.nan        in_epsg = parameters[13].value                  # output epsg         in_resampling = parameters[14].value            # output resampler method         in_snap = parameters[15].value                  # output snap alignment         in_rescale = parameters[16].value               # output rescale        in_cell_align = parameters[17].value            # output cell alignmnent             in_chunk_size = parameters[18].value            # chunk size                  # set up progess bar        arcpy.SetProgressor(type='default', message='Preparing query parameters...')                # get minimum bounding geom from input         bbox = arc.get_selected_layer_extent(in_studyarea_feat)                # get collections based on platform         collections = arc.prepare_collections_list(in_platform)                    # prepare start and end date times        in_from_date = arc.datetime_to_string(in_from_date)        in_to_date = arc.datetime_to_string(in_to_date)                # test        #stdout = sys.stdout         #sys.stdout = io.StringIO()                # fetch stac data         arcpy.SetProgressorLabel('Performing STAC query...')        feats = cog.fetch_stac_data(stac_endpoint=STAC_ENDPOINT,                                     collections=collections,                                     start_dt=in_from_date,                                     end_dt=in_to_date,                                     bbox=bbox,                                    slc_off=in_slc_off,                                    limit=RESULT_LIMIT)                                            #output = sys.stdout.getvalue()        #sys.stdout = stdout        #arcpy.AddMessage(output)                # count number of items        arcpy.AddMessage('Found {} {} scenes.'.format(len(feats), in_platform))                        # prepare band (i.e. stac assets) names        assets = arc.prepare_band_names(in_bands=in_bands,                                         in_platform=in_platform)                    # convert raw stac into dict with coord reproject, etc.        arcpy.SetProgressorLabel('Converting STAC data into useable format...')        meta, asset_table = cog.prepare_data(feats,                                              assets=assets,                                             bounds_latlon=bbox,                                              bounds=None,                                              epsg=in_epsg,                                              resolution=in_res,                                              snap_bounds=in_snap,                                             force_dea_http=True)                                                     # prepare resample and fill value types        resampling = in_resampling.lower()        fill_value = arc.prepare_fill_value_type(in_fill_value)                                                                                                  # convert assets to dask array        arcpy.SetProgressorLabel('Parallelising data...')        darray = cog.convert_to_dask(meta=meta,                                      asset_table=asset_table,                                      chunksize=in_chunk_size,                                     resampling=resampling,                                      dtype=in_dtype,                                      fill_value=fill_value,                                      rescale=in_rescale)                                             # prepare alignment type        cell_align = arc.prepare_cell_align_type(in_cell_align)        # generate coordinates and dimensions from metadata        arcpy.SetProgressorLabel('Building dataset metadata...')        coords, dims = cog.build_coords(feats=feats,                                        assets=assets,                                         meta=meta,                                        pix_loc=cell_align)                # build final xarray data array        arcpy.SetProgressorLabel('Finalising dataset...')        ds_name = 'stac-' + dask.base.tokenize(darray)        ds = xr.DataArray(darray,                          coords=coords,                          dims=dims,                          #attrs=attrs,                          name=ds_name                          )                                 # comvert to cleaner xarray dataset        ds = ds.to_dataset(dim='band')                # append attributes onto dataset        ds = cog.build_attributes(ds=ds,                                  meta=meta,                                   fill_value=fill_value,                                   collections=collections,                                   slc_off=in_slc_off,                                   bbox=bbox,                                  resampling=in_resampling)                                             # set up proper progress bar        arcpy.SetProgressor(type='step',                             message='Preparing query parameters...',                             min_range=0,                             max_range=len(assets) + 1)                                            # get list of dataset vars and iterate compute on each        for counter, data_var in enumerate(list(ds.data_vars), start=1):                    # start clock            start = time.time()                    # update progress bar            arcpy.SetProgressorLabel('Downloading band: {}...'.format(data_var))            arcpy.SetProgressorPosition(counter)                    # compute!            ds[data_var] = ds[data_var].compute()                        # notify time             duration = round(time.time() - start, 2)            arcpy.AddMessage('Band: {} took: {}s to download.'.format(data_var, duration))                # wrap up         arcpy.SetProgressorLabel('Exporting NetCDF...')        arcpy.SetProgressorPosition(counter + 1)                        # export netcdf to output folder        fn = os.path.join(out_folder_path, ds_name + '.nc')        ds.to_netcdf(fn)                # open netcdf as multidimensional raster         if in_open_as_mdr:                    # remove cloud and empty scenes                        # copy to mdr            mdr = arcpy.CopyRaster_management(in_raster=fn,                                               out_rasterdataset="mdr.crf")                          # add to current map            aprx = arcpy.mp.ArcGISProject('CURRENT')            m = aprx.activeMap            m.addDataFromPath(mdr)                    #arcpy.md.MakeMultidimensionalRasterLayer(                #in_multidimensional_raster=fn,                #out_multidimensional_raster_layer="in_memory/Buffers/{}.crf".format(ds_name),                #variables=["nbart_red", "nbart_green", "nbart_blue"])        # notify finish        arcpy.AddMessage('COG Fetch completed successfully.')                returnclass GDVSpectra(object):    def __init__(self):        """Define the tool (tool name is the name of the class)."""        self.label = "GDVSpectra"        self.description = "GDVSpectra contains functions that derive " \                           "potential groundwater dependent vegetation from " \                           "a time series of Landsat or Sentinel data."        self.canRunInBackground = False    def getParameterInfo(self):        """Define parameter definitions"""                # input netcdf file (temp)        par_nc_path = arcpy.Parameter(                        displayName="Input NetCDF file",                        name="in_nc_path",                        datatype="DEFile",                        parameterType="Required",                        direction="Input"                        )        # set file type to be netcdf only        par_nc_path.filter.list = ['nc']                # input study area shapefile (temp)        par_studyarea_feat = arcpy.Parameter(                                displayName="Input study area feature",                                name="in_studyarea_feat",                                datatype="GPFeatureLayer",                                parameterType="Required",                                direction="Input"                                )                                        # set study area to be polygon only        #par_studyarea_feat.filter.list = ['Polygon']                         # output folder location        par_out_folder_path = arcpy.Parameter(                                displayName="Output folder",                                name="out_folder_path",                                datatype="DEWorkspace",                                parameterType="Required",                                direction="Input"                                )        # in_platform        par_platform = arcpy.Parameter(                            displayName="Satellite platform",                            name="in_platform",                            datatype="GPString",                            parameterType="Required",                            direction="Input",                            category='Satellite query',                            multiValue=False                            )                                    # set default platform        par_platform.values = 'landsat'        par_platform.filter.list = ['landsat', 'sentinel']        # in_from_date        par_date_from = arcpy.Parameter(                            displayName="Date from",                            name="in_from_date",                            datatype="GPDate",                            parameterType="Required",                            direction="Input",                            category='Satellite query',                            multiValue=False                            )                                    # set in_from_date value        par_date_from.values = '2010/01/01'                # in_to_date        par_date_to = arcpy.Parameter(                        displayName="Date to",                        name="in_to_date",                        datatype="GPDate",                        parameterType="Required",                        direction="Input",                        category='Satellite query',                        multiValue=False                        )        # set in_from_date value        par_date_to.values = '2021/01/01'        # in_wet_months        par_wet_months = arcpy.Parameter(                            displayName="Wet month(s)",                            name="in_wet_months",                            datatype="GPString",                            parameterType="Required",                            direction="Input",                            multiValue=False                            )                                    # set default wet months        par_wet_months.values = '1, 2, 3'                # in_dry_months        par_dry_months = arcpy.Parameter(                            displayName="Dry month(s)",                            name="in_dry_months",                            datatype="GPString",                            parameterType="Required",                            direction="Input",                            multiValue=False                            )                                    # set default dry months        par_dry_months.values = '9, 10, 11'                # in_veg_idx        par_veg_idx = arcpy.Parameter(                        displayName="Vegetation index",                        name="in_veg_idx",                        datatype="GPString",                        parameterType="Required",                        direction="Input",                        multiValue=False                        )                                    # set default veg idx        par_veg_idx.value = 'mavi'        par_veg_idx.filter.type = 'ValueList'        par_veg_idx.filter.list = [            'ndvi',            'evi',             'savi',            'msavi',            'slavi',            'mavi',            'kndvi',            'tcg',            'tcb',            'tcw'            ]                # in_mst_idx        par_mst_idx = arcpy.Parameter(                        displayName="Moisture index",                        name="in_mst_idx",                        datatype="GPString",                        parameterType="Required",                        direction="Input",                        multiValue=False)                                    # set default mst idx        par_mst_idx.value = 'ndmi'        par_mst_idx.filter.type = 'ValueList'        par_mst_idx.filter.list = [            'ndmi',            'gvmi'            ]                    # set pvalue for zscore        par_zscore_pvalue = arcpy.Parameter(                                displayName="Z-score p-value",                                name="in_zscore_pvalue",                                datatype="GPDouble",                                parameterType="Optional",                                direction="Input",                                category='Outlier correction',                                multiValue=False)                                    # set default mst idx        par_zscore_pvalue.value = None                # set q upper for standardisation        par_ivt_qupper = arcpy.Parameter(                                displayName="Upper percentile",                                name="in_stand_qupper",                                datatype="GPDouble",                                parameterType="Optional",                                direction="Input",                                category='Standardisation',                                multiValue=False)                                    # set default mst idx        par_ivt_qupper.value = 0.99                # set q lower for standardisation        par_ivt_qlower = arcpy.Parameter(                                displayName="Lower percentile",                                name="in_stand_qlower",                                datatype="GPDouble",                                parameterType="Optional",                                direction="Input",                                category='Standardisation',                                multiValue=False)                                    # set default mst idx        par_ivt_qlower.value = 0.05        # combine parameters        parameters = [            par_nc_path,            par_studyarea_feat,            par_out_folder_path,            par_platform,            par_date_from,            par_date_to,            par_wet_months,             par_dry_months,             par_veg_idx,             par_mst_idx,             par_zscore_pvalue,            par_ivt_qupper,            par_ivt_qlower            ]                return parameters    def isLicensed(self):        """Set whether tool is licensed to execute."""        return True    def updateParameters(self, parameters):        """Modify the values and properties of parameters before internal        validation is performed.  This method is called whenever a parameter        has been changed."""                        return    def updateMessages(self, parameters):        """Modify the messages created by internal validation for each tool        parameter.  This method is called after internal validation."""        return    def execute(self, parameters, messages):        """The source code of the tool."""                # temp! remove future warning on pandas        import warnings        warnings.simplefilter(action='ignore', category=FutureWarning)                # imports        import os, sys        import numpy as np        import pandas as pd        import xarray as xr                # import tools        #sys.path.append('../../../shared') temp for demo        sys.path.append(r'C:\Users\262272G\Documents\GitHub\tenement-tools\shared')        sys.path.append(r'C:\Users\Lewis\Documents\GitHub\tenement-tools\shared')        import satfetcher, tools                # import gdvspectra module        #sys.path.append('../../../modules') temp for demo        sys.path.append(r'C:\Users\262272G\Documents\GitHub\tenement-tools\modules')        sys.path.append(r'C:\Users\Lewis\Documents\GitHub\tenement-tools\modules')        import gdvspectra                # notify user        arcpy.AddMessage('Preparing input parameters.')        # get netcdf file        in_nc_path = parameters[0].valueAsText        arcpy.AddMessage('Recieved NetCDF file: {0}.'.format(in_nc_path))                        # get study area feature        in_studyarea_feat = parameters[1].value        arcpy.AddMessage('Recieved study area file: {0}.'.format(in_studyarea_feat))                # get output folder        out_folder_path = parameters[2].valueAsText        arcpy.AddMessage('Recieved output folder path: {0}.'.format(out_folder_path))               # get platform        in_platform = parameters[3].value        arcpy.AddMessage('Recieved platform type: {0}.'.format(in_platform))                # get in_from_date        in_from_date = parameters[4].value        arcpy.AddMessage('Recieved from date: {0}.'.format(in_from_date))                # get in_to_date        in_to_date = parameters[5].value        arcpy.AddMessage('Recieved to date: {0}.'.format(in_to_date))                # clean up wet months         wet_month = parameters[6].value        if wet_month:            wet_month = [int(e) for e in wet_month.split(',')]                # clean up dry months         dry_month = parameters[7].value        if dry_month:            dry_month = [int(e) for e in dry_month.split(',')]                    # get veg_idx, mst_idx from parameters         veg_idx, mst_idx = parameters[8].value, parameters[9].value                # get zscore p-value        zscore_pvalue = parameters[10].value # fix                # get interpolation method         # todo full or half                # get q upper, q lower for invariant target         # todo                # set veg mask quantile for similairity        # todo                                        # notify user        arcpy.AddMessage('Initialising GDVSpectra tool.')        # load netcdf        arcpy.AddMessage('Loading provided NetCDF file.')        ds = satfetcher.load_local_nc(nc_path=in_nc_path,                                       use_dask=False,                                       conform_nodata_to=-9999)                  # conform band names from dea to basic        arcpy.AddMessage('Conforming band names.')        ds = satfetcher.conform_dea_ard_band_names(ds=ds,                                                    platform=in_platform)                # notify user        #arcpy.AddMessage('Creating a backup dataset for later.')                # make copy for ds for later cva work        #ds_backup = ds.copy(deep=True)                # get subset fo data for wet and dry season months        arcpy.AddMessage('Reducing dataset down to wet, dry months.')        ds = gdvspectra.subset_months(ds=ds,                                       month=wet_month + dry_month,                                      inplace=True)                # calculate vegetation and moisture indices        arcpy.AddMessage('Generating vege/moist indices: {0}'.format(veg_idx, mst_idx))        ds = tools.calculate_indices(ds=ds,                                      index=['mavi', 'ndmi'],                                      custom_name=['veg_idx', 'mst_idx'],                                      rescale=True,                                      drop=True)        # perform resampling        arcpy.AddMessage('Resampling dataset to annual wet/dry medians.')        ds = gdvspectra.resample_to_wet_dry_medians(ds=ds,                                                     wet_month=wet_month,                                                     dry_month=dry_month,                                                    inplace=True)        # persist memoru        #ds = ds.persist()                # perform outlier removal        if zscore_pvalue:            arcpy.AddMessage('Removing outliers via Z-Score.')            ds = gdvspectra.nullify_wet_dry_outliers(ds=ds,                                                      wet_month=wet_month,                                                      dry_month=dry_month,                                                      p_value=0.01, # todo link this to param                                                     inplace=True)        # remove any years missing wet, dry season         arcpy.AddMessage('Removing any years missing wet, dry seasons.')        ds = gdvspectra.drop_incomplete_wet_dry_years(ds=ds)        # fill any empty first, last years using back/forward fill        arcpy.AddMessage('Filling any empty first and last years.')        # temp! todo for demo        #ds = gdvspectra.fill_empty_wet_dry_edges(ds=ds,                                                 #wet_month=wet_month,                                                  #dry_month=dry_month,                                                 #inplace=True)                                                         # interpolate missing values         arcpy.AddMessage('Interpolating missing values for wet, dry seasons.')        # temp! todo for demo        #ds = gdvspectra.interp_empty_wet_dry(ds=ds,                                             #wet_month=wet_month,                                             #dry_month=dry_month,                                             #method='full', #todo link to param                                             #inplace=True)                                                     # standardise data to invariant targets derived from dry times        arcpy.AddMessage('Standardising data to dry season invariant targets.')        ds = gdvspectra.standardise_to_dry_targets(ds=ds,                                                    dry_month=dry_month,                                                    q_upper=0.99, # todo link to params                                                   q_lower=0.05, # todo link to params                                                   inplace=True)                                                           # calculate seasonal similarity        arcpy.AddMessage('Calculating seasonal similarity.')        ds_similarity = gdvspectra.calc_seasonal_similarity(ds=ds,                                                            wet_month=wet_month,                                                            dry_month=dry_month,                                                            q_mask=0.9, # todo link to params                                                            inplace=True)                                                                    # calculate gdv likelihood        arcpy.AddMessage('Calculating groundwater dependent vegetation likelihood.')        ds = gdvspectra.calc_likelihood(ds=ds,                                         ds_similarity=ds_similarity,                                        wet_month=wet_month,                                         dry_month=dry_month)                # todo - temp - get median all time         ds = ds.median('time')                                                                         # export likelihood as netcdf         out_path_file = os.path.join(out_folder_path, 'ds_like.nc')        arcpy.AddMessage('Exporting GDV likelihood as netcdf to: {0}.'.format(out_path_file))        tools.export_xr_as_nc(ds=ds, filename=out_path_file)                # notify user        arcpy.AddMessage('Preparing data for map.')                                      # get current project and map todo handle exception        aprx = arcpy.mp.ArcGISProject("CURRENT")        m = aprx.listMaps("Map")[0]                # temp halt adding to map for now        arcpy.env.addOutputsToMap = False                # todo - temp - show a layer        nc_layer = arcpy.MakeNetCDFRasterLayer_md(in_netCDF_file=out_path_file,                                                   variable='like',                                                   x_dimension='x',                                                   y_dimension='y',                                                  out_raster_layer='like',                                                   band_dimension='',                                                   dimension_values='',                                                   value_selection_method='')                                                           # create layer        out_path_tif = os.path.join(out_folder_path, 'like.tif')        tif_layer = arcpy.CopyRaster_management(in_raster=nc_layer,                                                 out_rasterdataset=out_path_tif)        # turn on add to map        arcpy.env.addOutputsToMap = True        # define projection in albers        tif_layer = arcpy.management.DefineProjection(in_dataset=tif_layer,                                                       coor_system=arcpy.SpatialReference(3577))        # refresh toc and map        m.addDataFromPath(tif_layer)                                                      # close xarrays, arcpy objects        del ds, ds_similarity #, ds_backup        del nc_layer, aprx, m         # notify user        arcpy.AddMessage('Generated GDV likelihood successfully.')                return