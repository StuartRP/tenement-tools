{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete this!\n",
      "remove this\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import certifi\n",
    "\n",
    "# we need to set gdal and rasterio defaults. this will need thought.\n",
    "os.environ['GDAL_DATA']  = r'C:\\Program Files\\ArcGIS\\Pro\\Resources\\pedata\\gdaldata' # in order for rasterio gdal affine and crs to work\n",
    "os.environ.setdefault(\"CURL_CA_BUNDLE\", certifi.where()) # in order for xr open_rasterioor rasterion.open to work\n",
    "\n",
    "import sys\n",
    "import gdal\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "\n",
    "sys.path.append(r'C:\\Users\\Lewis\\Desktop')\n",
    "import work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bounds = [\n",
    "    118.928375244140611,\n",
    "    -22.816061209792938,\n",
    "    119.165267944335921,\n",
    "    -22.681182933819271\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 items for platform: ga_ls5t_ard_3\n"
     ]
    }
   ],
   "source": [
    "def fetch_stac_items(bbox, start_date, end_date, collections, limit, stac_end_url):\n",
    "    \n",
    "    # imports\n",
    "    from satsearch import Search\n",
    "\n",
    "    # search stac\n",
    "    search = Search(bbox=bbox,\n",
    "                datetime='{}/{}'.format(start_date, end_date),\n",
    "                collections=collections,\n",
    "                limit=limit,\n",
    "                url=stac_end_url)\n",
    "\n",
    "    # notify number of items\n",
    "    print('Found {} items for platform: {}'.format(search.found(), collections))\n",
    "    \n",
    "    # get items\n",
    "    items = search.items(limit=limit)\n",
    "    \n",
    "    # do some other\n",
    "    \n",
    "    return items\n",
    "\n",
    "url = 'https://explorer.sandbox.dea.ga.gov.au/stac/'\n",
    "collections = ['ga_ls5t_ard_3', 'ga_ls7e_ard_3', 'ga_ls8c_ard_3']\n",
    "\n",
    "items = fetch_stac_items(bbox=gdf_bounds, \n",
    "                         start_date='1990-01-01', \n",
    "                         end_date='1990-12-31', \n",
    "                         collections='ga_ls5t_ard_3', \n",
    "                         limit=1000, \n",
    "                         stac_end_url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set inputs\n",
    "assets=['nbart_blue', 'nbart_green', 'nbart_red']\n",
    "bounds_latlon=gdf_bounds\n",
    "bounds=None\n",
    "epsg=3577\n",
    "resolution=30\n",
    "snap_bounds=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, convert stac items to plain dicts\n",
    "# plain_items = items_to_plain\n",
    "# just does this:\n",
    "plain_items = [item._data for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort whole dict by datetime via sorted func\n",
    "plain_items = sorted(\n",
    "    plain_items,\n",
    "    key=lambda item: item[\"properties\"].get('datetime', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START PREPARE FUNC\n",
    "# now we call prepare itmes function\n",
    "out_epsg = epsg\n",
    "out_bounds = bounds # not bounds_latlon, this gets none if latlon bounds used\n",
    "\n",
    "if resolution is not None and not isinstance(resolution, tuple):\n",
    "    resolution = (resolution, resolution)\n",
    "out_resolutions_xy = resolution\n",
    "\n",
    "# dont need to do all the work with assets, we always want same\n",
    "asset_ids = assets\n",
    "\n",
    "# creates a table with structure for \n",
    "ASSET_TABLE_DT = np.dtype([(\"url\", object), (\"bounds\", \"float64\", 4)])\n",
    "asset_table = np.full((len(plain_items), len(asset_ids)), None, dtype=ASSET_TABLE_DT) # fills numpy array of shape (3,) filled with nan. holds scene info\n",
    "\n",
    "# if items empty, throw error\n",
    "if len(plain_items) == 0:\n",
    "    raise ValueError(\"No items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import pyproj\n",
    "\n",
    "@lru_cache(maxsize=32) # this ensures we only really calc once if same epsgs\n",
    "def cached_transform(from_epsg, to_epsg, skip_equivalent, always_xy):\n",
    "    return pyproj.Transformer.from_crs(from_epsg, \n",
    "                                       to_epsg, \n",
    "                                       skip_equivalent=True, \n",
    "                                       always_xy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_from_affine(af, ysize, xsize, from_epsg, to_epsg):   \n",
    "    \n",
    "    ul_x, ul_y = af * (0, 0)\n",
    "    ll_x, ll_y = af * (0, ysize)\n",
    "    lr_x, lr_y = af * (xsize, ysize)\n",
    "    ur_x, ur_y = af * (xsize, 0)\n",
    "\n",
    "    xs = [ul_x, ll_x, lr_x, ur_x]\n",
    "    ys = [ul_y, ll_y, lr_y, ur_y]\n",
    "\n",
    "    if from_epsg != to_epsg:\n",
    "        #transformer = pyproj.Transformer.from_crs(from_epsg, \n",
    "                                                  #to_epsg, \n",
    "                                                  #skip_equivalent=True, \n",
    "                                                  #always_xy=True)\n",
    "        transformer = cached_transform(from_epsg, \n",
    "                                       to_epsg, \n",
    "                                       skip_equivalent=True, \n",
    "                                       always_xy=True)\n",
    "        \n",
    "        xs_proj, ys_proj = transformer.transform(xs, ys, errcheck=True)\n",
    "    else:\n",
    "        xs_proj = xs\n",
    "        ys_proj = ys\n",
    "\n",
    "    return min(xs_proj), min(ys_proj), max(xs_proj), max(ys_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_overlap(*bounds):\n",
    "    min_xs, min_ys, max_xs, max_ys = zip(*bounds)\n",
    "    return max(min_xs) < min(max_xs) and max(min_ys) < min(max_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snapped_bounds(bounds, resolutions_xy):\n",
    "    import math\n",
    "    \n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    xres, yres = resolutions_xy\n",
    "\n",
    "    minx = math.floor(minx / xres) * xres\n",
    "    maxx = math.ceil(maxx / xres) * xres\n",
    "    miny = math.floor(miny / yres) * yres\n",
    "    maxy = math.ceil(maxy / yres) * yres\n",
    "\n",
    "    return (minx, miny, maxx, maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D66140B0-0277-45FF-AE18-A787BE3D4AAF:9: DeprecationWarning: skip_equivalent is deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# start working items\n",
    "for item_i, item in enumerate(plain_items):\n",
    "    item_epsg = item['properties'].get(\"proj:epsg\")\n",
    "    item_bbox = item['properties'].get(\"proj:bbox\")\n",
    "    item_shape = item['properties'].get(\"proj:shape\")\n",
    "    item_transform = item['properties'].get(\"proj:transform\")\n",
    "    \n",
    "    item_bbox_proj = None\n",
    "    for asset_i, a_id in enumerate(asset_ids):\n",
    "        try:\n",
    "            asset = item['assets'].get(a_id)\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "        asset_epsg = asset.get(\"proj:epsg\", item_epsg)\n",
    "        asset_bbox = asset.get(\"proj:bbox\", item_bbox)\n",
    "        asset_shape = asset.get(\"proj:shape\", item_shape)\n",
    "        asset_transform = asset.get(\"proj:transform\", item_transform)\n",
    "        asset_affine = None\n",
    "        \n",
    "        # stackstac has logic to use scene crs if projection not provided. we always want to project, so ignore\n",
    "        out_epsg = int(out_epsg)\n",
    "        \n",
    "        # project bounds to requested epsg\n",
    "        if bounds_latlon is not None and out_bounds is None:\n",
    "            \n",
    "            with rasterio.Env(CURL_CA_BUNDLE=certifi.where()) as env:\n",
    "                from rasterio.warp import transform_bounds\n",
    "\n",
    "                # convert selected bounding box to epsg in output scene, liek so V\n",
    "                l, b, r, t = bounds_latlon[0], bounds_latlon[1], bounds_latlon[2], bounds_latlon[3]\n",
    "                out_bounds = bounds = transform_bounds(src_crs=4326, \n",
    "                                                       dst_crs=out_epsg, \n",
    "                                                       left=l, bottom=b, right=r, top=t)\n",
    "        \n",
    "        # if asset bbox exists, use that, else use scene bbox\n",
    "        # not doing that\n",
    "        # use asset transform instead\n",
    "        import affine\n",
    "        if asset_transform is not None and asset_shape is not None and asset_epsg is not None:\n",
    "            asset_affine = affine.Affine(*asset_transform[:6]) # get affine\n",
    "            \n",
    "            # check the lru_cache thing here in stackstac, might go faster\n",
    "            asset_bbox_proj = bounds_from_affine(asset_affine,\n",
    "                                                 asset_shape[0],\n",
    "                                                 asset_shape[1],\n",
    "                                                 asset_epsg,\n",
    "                                                 out_epsg)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('No scene transform')\n",
    "        \n",
    "        # create bounds. simplified this\n",
    "        if bounds is None:\n",
    "            if asset_bbox_proj is None:\n",
    "                raise ValueError('not enough spatial info')\n",
    "            \n",
    "            if out_bounds is None:\n",
    "                out_bounds = asset_bbox_proj\n",
    "            else:\n",
    "                print('code up geom_utils.union_bounds(asset_bbox_proj, out_bounds)')\n",
    "                \n",
    "        else:\n",
    "            if asset_bbox_proj is not None and not bounds_overlap(asset_bbox_proj, bounds):\n",
    "                continue\n",
    "                \n",
    "        # do resolution\n",
    "        if resolution is None:\n",
    "            print('do some work for resolution user not provided')\n",
    "            \n",
    "        # store information\n",
    "        # creates row in array that has 1 row per scene, n columns per requested band where (url, [l, b, r, t])\n",
    "        href = asset[\"href\"].replace('s3://dea-public-data', 'https://data.dea.ga.gov.au')\n",
    "        asset_table[item_i, asset_i] = (href, asset_bbox_proj)\n",
    "        \n",
    "print('Done!')\n",
    "\n",
    "# now, move things over to new vars\n",
    "# he casts out_bounds to a bbox object, which is just a tuple of l, r, t, b or whatever\n",
    "# does same for out_resolutions_xy\n",
    "# out_epsg also same, converted to int\n",
    "\n",
    "# snap bounds?\n",
    "if snap_bounds:\n",
    "    out_bounds = snapped_bounds(out_bounds, out_resolutions_xy)\n",
    "\n",
    "# converts values to a object\n",
    "#spec = RasterSpec(\n",
    "        #epsg=out_epsg,\n",
    "        #bounds=out_bounds,\n",
    "        #resolutions_xy=out_resolutions_xy,)\n",
    "        \n",
    "# prepare spec dictionary\n",
    "trans = affine.Affine(out_resolutions_xy[0],   # xscale\n",
    "                      0.0,\n",
    "                      out_bounds[0],  # xoff\n",
    "                      0.0,\n",
    "                      -out_resolutions_xy[1],  # yscale\n",
    "                      out_bounds[3],  # yoff\n",
    "                     )\n",
    "\n",
    "\n",
    "def get_shape(out_bounds, out_resolutions_xy):\n",
    "    minx, miny, maxx, maxy = out_bounds\n",
    "    xres, yres = out_resolutions_xy\n",
    "    width = int((maxx - minx + (xres / 2)) / xres)\n",
    "    height = int((maxy - miny + (yres / 2)) / yres)\n",
    "\n",
    "    return (height, width)    \n",
    "    \n",
    "\n",
    "    # This is how GDAL rounds/snaps the calculation, so we do it too\n",
    "    # https://github.com/OSGeo/gdal/blob/00615775bff0681a7fbce17eb187dcfc0e000c15/gdal/apps/gdalwarp_lib.cpp#L3394-L3399\n",
    "    # (it's not quite the same as `round`)\n",
    "    width = int((maxx - minx + (xres / 2)) / xres)\n",
    "    height = int((maxy - miny + (yres / 2)) / yres)\n",
    "\n",
    "    return (height, width)\n",
    "\n",
    "\n",
    "spec = {'epsg': out_epsg,\n",
    "        'bounds': out_bounds,\n",
    "        'resolutions_xy': out_resolutions_xy,\n",
    "        'shape': get_shape(out_bounds, out_resolutions_xy),\n",
    "        'transform': trans,\n",
    "        'vrt_params': {\n",
    "            'crs': out_epsg,\n",
    "            'transform': trans,\n",
    "            'height': get_shape(out_bounds, out_resolutions_xy)[0],\n",
    "            'width': get_shape(out_bounds, out_resolutions_xy)[1]\n",
    "        }\n",
    "       }        \n",
    "\n",
    "# drop items/assets where must be skipped. either asset missed, or out of bounds\n",
    "# same size as table\n",
    "isnan_table = np.isnan(asset_table[\"bounds\"]).all(axis=-1) # uses bounds because other object isnan doesnt work\n",
    "item_isnan = isnan_table.all(axis=1)  # any items all empty?\n",
    "asset_id_isnan = isnan_table.all(axis=0) # bands assets all empty?\n",
    "\n",
    "# remove nan items... np.ix_ chooses any row and column where not nan\n",
    "if item_isnan.any() or asset_id_isnan.any():\n",
    "    asset_table = asset_table[np.ix_(~item_isnan, ~asset_id_isnan)]\n",
    "    asset_ids = [id for id, isnan in zip(asset_ids, asset_id_isnan) if not isnan]\n",
    "    items = [item for item, isnan in zip(items, item_isnan) if not isnan]\n",
    "    \n",
    "# returns \n",
    "#return asset_table, spec, asset_ids, plain_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.enums import Resampling\n",
    "from work import items_to_dask\n",
    "\n",
    "arr = items_to_dask(asset_table=asset_table,\n",
    "                    spec=spec,\n",
    "                    chunksize=512,\n",
    "                    dtype=np.dtype('int16'),\n",
    "                    resampling=Resampling.nearest,\n",
    "                    fill_value=-999,\n",
    "                    rescale=True,\n",
    "                    reader=None,\n",
    "                    gdal_env=None,\n",
    "                    errors_as_nodata=()\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from work import to_coords, to_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.DataArray(\n",
    "    arr,\n",
    "    *to_coords(\n",
    "        plain_items,\n",
    "        asset_ids,\n",
    "        spec,\n",
    "        xy_coords='topleft',\n",
    "        properties=None,\n",
    "        band_coords=True\n",
    "    ),\n",
    "    attrs=to_attrs(spec),\n",
    "    name=\"stackstac-\" + dask.base.tokenize(arr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 39.4s\n",
      "Wall time: 39.5 s\n"
     ]
    }
   ],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "%time ds = dataset.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.to_dataset(dim='band')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf(r'D:\\test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
